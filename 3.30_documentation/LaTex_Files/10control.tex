\section{Control File}
\subsection{Overview of Control File}
These listed model features are denoted in the control file in the following order:
	\begin{enumerate}
		\itemsep0em
		\item Number of growth patterns and sub-morphs
		\item Design matrix for assignment of recruitment to area/season/growth pattern
		\item Design matrix for movement between areas
		\item Definition of time blocks that can be used for time-varying parameters
		\\
		\item Specification for growth and fecundity
		\item Natural mortality and growth parameters for each gender x growth pattern
		\item Maturity, fecundity and weight-length for each gender
		\item Recruitment distribution parameters for each area, season, growth pattern
		\item Cohort growth deviation
		\item Catch Multiplier
		\item Fraction female
		\item Environmental link parameters for any mortality-growth (MG) parameters that use a link
		\item Time-varying setup for any MG parameters that use blocks
		\item Seasonal effects on biology parameters
		\item Phase for any MG parameters that use annual deviations
		\\
		\item Spawner-recruitment parameters
		\item Recruitment deviations
		\\
		\item Method for calculating fishing mortality (F)
		\item Initial equilibrium F for each fleet
		\\
		\item Catchability (Q) setup for each fleet and survey
		\item Catchability parameters
		\\
		\item Length selectivity, retention, discard mortality setup for each fleet and survey
		\item Age selectivity setup for each fleet and survey
		\item Parameters for length selectivity, retention, discard mortality for each fleet and survey
		\item Parameters for age selectivity for each fleet and survey
		\item Environmental link parameters for any selectivity/retention parameters that use a link
		\item Time-varying setup for any selectivity/retention parameters that use blocks
		\item Phase for any selectivity/retention parameters that use random annual deviation
		\\
		\item Tag-recapture parameters
		\\
		\item Variance adjustments
		\item Lambdas for likelihood components
	\end{enumerate}

\subsection{Parameter Line Elements}
A primary role of the SS control file is to define the parameters to be used by the model.  The general syntax of a parameter line is described here.  Parameter lines will be used in three sections of the control file: (1) natural mortality and growth; (2) spawner-recruitment, initial F and catchability; and (3) selectivity.  The first seven elements of a parameter line are used in every section and will be referred to as a short parameter line.  The remaining elements are used just in sections (1) and (3).  Each parameter line contains:

\begin{center}
	\begin{tabular}{p{2cm} p{3cm} p{10cm}}
		Column & Element & Description\\
		\hline
		1 & LO & Minimum value for the parameter\\
		2 & HI & Maximum value for the parameter\\
		3 & INIT & Initial value for the parameter.  If the SS3 PAR file is read, it overwrites these INIT values.\\
		4 & Prior Value & Expected value for the parameter.  This value is ignored if the prior type is -1 or 1.\\
		5 & Prior Type  & -1 = none, 0 = normal, 1 = symmetric beta, 2 = full beta, 3 = lognormal with bias adjustment, 5 = gamma\\
		5 & Prior StDev & Standard deviation for the prior, used to calculate likelihood of the current parameter value. This value is ignored if prior type is -1. \\
		6 & PHASE & Phase in which parameter begins to be estimated.  A negative value causes the parameter to retain its INIT value (or value read from the PAR file).\\
		%\hline
		 & & \\
		\multicolumn{3}{l}{\parbox{16cm}{Short parameter lines have only the above 7 elements.  The full parameter line syntax for the Mortality-Growth and Selectivity sections provides additional controls to give the parameter time-varying properties.  These are listed briefly below and described in more detail in the section Time Varying Parameter Options found at the end of the control file syntax section.}}\\
		 & & \\
		%\hline
		8 & ENV & Create a linkage to an input environmental time-series\\
		9 & Use Dev & Invokes use of the deviation vector \\
		10 & Dev min yr & Beginning year for the deviation vector \\
		11 & Dev max yr & Ending year for the deviation vector\\
		12 & Dev StDev & Standard deviation for elements in the deviation vector \\
		13 & USE-BLOCK & Set up blocks or parameter trends\\
		14 & BLOCK-TYPE & Function form for the block offset\\
		\hline
	\end{tabular}
\end{center}

\subsection{Control File Syntax}
The control file is described here using a rather complex set-up with 2 seasons, 2 areas, 2 growth morphs, 2 genders, and 3 sub-morphs in order to demonstrate the order and interdependence of various factors.
\\
\\
Terminology:
\begin{itemize}
	\item Where the term “COND” appears in the value column of this documentation (it does not actually appear in the control file), it indicates that the following section is omitted except under certain conditions, or that the factors included in the following section depend upon certain conditions.
	\item In most cases, the description in the Definition column is the same as the label output to the control.ss\textunderscore new file.
\end{itemize}


\begin{center}

	\begin{longtable}{p{0.5cm} p{2cm} p{12cm}}

		\multicolumn{2}{l}{Typical Value} & Description and Options\\
		\hline
		\endfirsthead

		\multicolumn{2}{l}{Typical Value} & Description and Options\\
		\hline
		\endhead

		\hline
		\endfoot

		\endlastfoot

		\multicolumn{2}{l}{\#C comment } & Comments beginning with \#C at the top of the file will be retained and included in output  \\
		\hline

		2 & & N growth patterns (GP)  \\
		\hline

		3 & & Number of sub-morphs within a growth pattern. Permissible values are 1, 3, 5 only.  Typical value is 1.  Values of 3 or 5 allow exploration of size-dependent survivorship. \\
		\hline

		\multicolumn{2}{l}{COND > 1}& \multicolumn{1}{l}{\parbox{12cm}{Following 2 lines are conditional on N sub-morphs > 1}} \\

		& 0.7 & Morph between/within stdev ratio. Ratio of the amount of growth variability between sub-morphs to within sub-morphs.\\
		\hline

		& 0.2 0.6 0.2 & Distribution among sub-morphs. Enter custom vector or enter -1 to first value of vector to get a normal approximation: (0.15, 0.70, 0.15) for 3 sub-morphs, (0.031, 0.237, 0.464, 0.237, 0.031) for 5 sub-morphs.\\
		\hline

		1 & & Recruitment distribution method.  Options: 1 = use the 3.24 or earlier setup, 2 = main effects for GP, settle timing, and area, 3 = each settle entity, and 4 = none when N GP*Nsettle=1\\
		\hline

		1 & & Number of recruitment settlement assignments. Options: 1 = global, 2 = by area\\
		\hline

		\multicolumn{2}{l}{COND = 1}&\multicolumn{1}{l}{\multirow{1}{12cm}[-0.1cm]{\parbox{12.5cm}{Only read if recruitment distribution method is set to 1 (3.24 and earlier version)}}}\\
		\\
		& 0 & \multicolumn{1}{l}{\multirow{1}{12cm}[0cm]{\parbox{12.5cm}{Year x Area x Settlement Event Interaction Requested}}}\\
		\hline

		\multicolumn{2}{l}{1 1 1}& \multicolumn{1}{l}{\multirow{1}{12cm}[-0.1cm]{\parbox{12.5cm}{Recruitment assignment to GP, season, area (for each settlement event).}}}\\
		\\
		\hline

		\multicolumn{2}{l}{COND:}& \multicolumn{1}{l}{\multirow{1}{12cm}[-0.1cm]{\parbox{12.5cm}{If there are multiple GP, season, and areas, specify the additional lines:}}}\\
		\\
		& 1 1 1 & \multicolumn{1}{l}{\parbox{12.5cm}{Recruitment assignment to GP1, season 1, area 1}}\\
		& 2 1 2 & \multicolumn{1}{l}{\parbox{12.5cm}{Recruitment assignment to GP1, season 1, area 2}}\\
		& 2 1 1 & \multicolumn{1}{l}{\parbox{12.5cm}{Recruitment assignment to GP2, season 1, area 1}}\\
		& 2 2 2 & \multicolumn{1}{l}{\parbox{12.5cm}{Recruitment assignment to GP2, season 2, area 2}}\\
		\hline

		\multicolumn{2}{l}{COND:} & \multicolumn{1}{l}{If N areas > 1:}\\
		& 0 & \multicolumn{1}{l}{\parbox{12.5cm}{Movement: Only read following movement section if N areas > 1}}\\
		\hline

		\multicolumn{2}{l}{COND > 0 } & \multicolumn{1}{l}{\multirow{1}{12cm}[-0.1cm]{\parbox{12.5cm}{Following lines are conditional if movement is selected:}}}\\

		& 4 & \multicolumn{1}{l}{N movement definitions}\\

		& 0.60 & \multirow{1}{12cm}{First age that moves. Real, not integer age at the beginning of season.  This control primarily used to keep new recruits from moving until after their first year.}\\
		\\
		\\
		& 1 1 1 2 4 10 & \multicolumn{1}{l}{\multirow{5}{6cm}{\parbox{12cm}{The four requested movement definitions appear here.  Each definition specifies: season, GP source area, destination area, min age, max age. The rate of movement will be controlled by the movement parameters later.  Here the minage and maxage controls specify the range over which the movement parameters are active.}}}\\
		& 1 1 2 1 4 10 &  \\
		& 1 2 1 2 4 10 &  \\
		& 1 2 2 1 4 10 &  \\
		\\
		\hline
		3 & & \multirow{1}{6cm}[-0.1cm]{\parbox{12cm}{Number of block patterns. These patterns can be referred to in the parameter sections to create a separate parameter value for each block.}}\\
		\\
		\\
		\hline
		\multicolumn{2}{l}{COND:} & \multicolumn{1}{l}{Following inputs are omitted if N Block patterns equals 0}\\
		& \multirow{1}{2cm}[-0.1cm]{ 3 2 1 } & Blocks per pattern\\
		\\
		& \multirow{1}{2cm}[-0.1cm]{1975 1985 1986 1990 1995 2001} & \multirow{3}{12cm}[-0.10cm]{Beginning and ending years for blocks in design 1; years not assigned to a block period retain the baseline value for a parameter that uses this pattern.}\\
		\\
		\\
		\\
		& \multirow{1}{2cm}[-0.1cm]{1987 1990 1995 2001} & \multirow{1}{12cm}[-0.1cm]{Beginning and ending years for blocks in design 2.}\\
		\\
		\\
		& \multirow{1}{2cm}[-0.1cm]{1999 2002} & \multirow{1}{12cm}[-0.10cm]{Beginning and ending years for blocks in design 3.}\\
		\\
		\hline
	\end{longtable}
\end{center}

\subsubsection{Biology}
This section controls the biology parameters.  These include:  natural mortality, growth, maturity, fecundity, distribution of recruitment, and movement.  Collectively, these are referred to as the MG parameters.  The top of the biology section includes several factors that control the number of parameters to be subsequently read and the method by which SS will use these parameters.

\begin{center}

	\begin{longtable}{p{0.5cm} p{2cm} p{12cm}}

		\multicolumn{2}{l}{Typical Value} & Description and Options\\
		\hline
		\endfirsthead

		\multicolumn{2}{l}{Typical Value} & Description and Options\\
		\hline
		\endhead

		%\hline
		\endfoot

		\endlastfoot

		1 & & Natural Mortality Option:\\
		  & & 0 = A single parameter\\
		  & & 1 = N breakpoints\\
		  & & 2 = Lorenzen \\
		  & & 3 = Read age specific M and do not do seasonal interpolation\\
		  & & \multirow{1}{12cm}[-0.1cm]{4 = Read age specific and do seasonal interpolation, if appropriate}\\
		\hline

	   \multicolumn{2}{l}{COND = 0} & No additional natural mortality controls \\
	   \multicolumn{2}{l}{COND = 1} & \\
	   & 4 & \multirow{1}{12cm}[-0.1cm]{Number of breakpoints.  A value of 2 would correspond to the M pattern as defined in SS V2.  Then read a vector of ages for these breakpoints (e.g. corresponding to natM\textunderscore amin and natM\textunderscore amax in SS V2). Later, per gender x GP, read N parameters for the natural mortality at each breakpoint.}
	   \\
	   \\
	   \\
	   \\
	   \\
	   & 2.0 4.5 9.0 15.0 & Vector of age breakpoints \\
	   \multicolumn{2}{l}{COND = 2}& \\
	   & 4 & \multirow{1}{12cm}[-0.1cm]{Lorenzen Natural Mortality: read one additional value that is the reference age (integer) (\hyperlink{Lorenzen}{\textit{click here for more information}}). Later read one parameter for each gender x GP that will be the M at the reference age.  Other ages will have an M scaled to its body size-at-age.  However, if sub-morphs are used, all will have the same M a their growth pattern.  Lorenzen M calculation will be updated if the starting year growth parameters are active, but if growth parameters vary during the time-series, the M is not further updated.  So be careful in using Lorenzen when there is time-varying growth.}\\
	   \\
	   \\
	   \\
	   \\
	   \\
	   \\
	   \\
	   \\
	   \\
	   \multicolumn{2}{l}{COND = 3 or 4} & \multirow{1}{12cm}[-0.1cm]{Do not read any natural mortality parameters.  With option 2, these M values are held fixed for the integer age (no seasonality or birth season considerations). With option 4, there is seasonal interpolation based on real age, just as in options 1 and 2.}\\
	   \\
	   \\
	   \\
	   & 0.20 0.25 ... 0.20 0.23 ... & \multirow{1}{12cm}[-0.1cm]{Age-specific M values: row 1 is female GP1, row 2 is female 2 GP2, row 3 is male GP1, etc.}\\
	   \hline

	   \pagebreak

	   1 & & Growth Model: \\
	     & & 1 = von Bertalanffy (2 parameters)\\
	     & & 2 = Schnute's generalized growth curve (aka Richards curve) with 3 parameters \\
	     & & 3 = von Bertalanffy with age-specific \textit{k} deviations for specified range of ages\\
	   \hline

	   1.66 & & Growth Amin (A1): Reference age for first size-at-age parameter (\hyperlink{A1}{\textit{click here for more information}})\\
	   \hline

	   25 & & Growth Amax (A2): Reference age for second size-at-age parameter.\\
	   \hline

	   \multicolumn{2}{l}{COND = 3} & Growth option age-specific \textit{k}\\
	   & 5 & Minimum age for age-specific \textit{k}\\
	   & 7 & Maximum age for age-specific \textit{k}\\
	   \hline

	   0 & & Standard deviation added to length-at-age: Enter 0.10 to mimic SS2 V1.xx. Recommend using a value of 0.0.  \hyperlink{A1}{(\textit{click here for more information})}\\
	   \hline
	   1 & & CV Pattern \\
	     & & 0: CV=f(LAA), so the 2 parameters are in terms of CV of the distribution of length-at-age and the interpolation between these 2 parameters is a function of mean length-at-age.\\
	     & & 1: CV=f(A), so interpolation is a function of age.\\
	     & & 2: SD=f(LAA), so parameters define the standard deviations of length-at-age and interpolation is a function of mean length-at-age.\\
	     & & 3: SD=f(A) \\
	     & & 4: Lognormal distribution of size-at-age.  Input parameters will specify the standard deviation of loge size at age.  E.g. entered values will typically be between 0.05 and 0.15.  A bias adjustment is applied so the lognormal distribution of size-at-age will have the same mean size as when a normal distribution is used.\\
	   \hline

	   2 & & Maturity Option: \\
	     & & 1 = length logistic,\\
	     & & 2 = age logistic,\\
	     & & 3 = read age-maturity for each female GP\\
	     & & 4 = read an empirical age-maturity vector for all ages\\
	     & & 5 = read empirical age-fecundity and body weight-at-age from separate file, wtatage.ss.  Allows for reading time series of input. See section \hyperlink{WAA}{\textit{Empirical Wt-at-Age}} for details. NOTE:  need to read 2 parameters even if option 3, 4, or 5 is selected.\\
	     & & 6 = read an empirical length-maturity vector by population length bin (available in v3.24q)\\
	   \hline

	   \multicolumn{2}{l}{COND = 3 or 4} & Maturity Option\\
	   & 0 0.05 0.10 ... & Vector of age-specific maturity or fecundity.  One row of length Nages + 1 for each female GP\\
	   \multicolumn{2}{l}{COND = 6} & Maturity Option\\
	   & 0 0.05 0.10 ... & Vector of length-specific maturity or fecundity.  One row of length of the population length bins for each female GP\\
	   \hline

	   1 & & First Mature Age: Overridden if maturity option is 3, 4, or 5, but still must exist here.  Otherwise, all ages below the first mature age will have maturity set to zero.\\
	   \hline

	   1 & & Fecundity Option (irrelevant if maturity option is 4 or 5):\\
	     & & 1 = to  interpret the 2 egg parameters as linear eggs/kg on body weight (current SS default),  so fecundity = $wt * (a+b*wt)$, so value of a=1, b=0 causes eggs to be equivalent to spawning biomass.\\
	     & & 2 = to set fecundity= $a*L^ b$\\
	     & & 3 = to set fecundity= $a*W^ b$, so values of a=1, b=1 causes fecundity to be equiv to spawning biomass\\
	     & & 4 = fecundity = $a+b*L$\\
	     & & 5 = Eggs = $a+b*wt$\\
	  \hline

	  0 & & Hermaphroditisim Option:\\
	   &  & 0 = not used, \\
	   &  & 1 = invoke female to male transition, \\
	   &  & -1 = invoke male to female transition \\
	  \hline

	  \multicolumn{2}{l}{COND = 1}& Read 2 lines below if hermaphroditism. is selected; also read 3 parameters after reading the male weight-length parameter\\
	  & -1 & Hermaphroditism Season: \\
	  &    & -1 to do transition at the end of each season (after mortality and before movement)\\
	  &    & <positive integer> to select just one season\\
	  \\
	  & 1  & Include males in spawning biomass \\
	  &    & 0 = no males in spawning biomass \\
	  &    & 1 = simple addition of males to females\\
	  &    & xx = more options to come later \\
	  \hline

	  2 & & Parameter Offset Method \\
	    & & 1 = direct assignment \\
	    & & 2 = for each GP x gender, parameter defines offset from gender 1, offsets are in exponential terms, so for example, old\textunderscore male M = old\textunderscore female M * exp(old\textunderscore male parameter)\\
	    & & 3 = for each GP x gender, parameter defines offset from GP 1 gender 1.  For females, given that “natM option” is breakpoint and there are two breakpoints, parameter defines offset from early age (e.g., old\textunderscore female\textunderscore M = young\textunderscore female\textunderscore M * exp(old\textunderscore female\textunderscore M\textunderscore parameter). For males, given that “natM option” is breakpoint and there are two breakpoints, parameter is defined as offset from females AND from early age (e.g., old\textunderscore male\textunderscore M = young\textunderscore female\textunderscore M * exp(young\textunderscore male\textunderscore M\textunderscore parameter) * exp(old\textunderscore male\textunderscore M\textunderscore parameter)).\\
	 \hline

	 1 & & Time-varying adjustment constraint:\\
	   & & 1 = standard parameter adjustments for environmental, block, and deviations are not constrained by bounds \\
	   & & 2 = logistic transform - parameter adjustments use a logistic transformation to assure that adjusted parameter value stays within bounds of base parameter \\
	   & & 3: standard with no bound check \\
	 \hline

	\end{longtable}
\end{center}



\subsubsection{Read Mortality-Growth Parameters}
Next, SS reads the MG parameters in generally the following order (may vary based on selected options):

\begin{center}
	\begin{longtable}{p{1cm} p{2.5cm} p{10cm}}

		Parameter& & Description\\
		\hline
		\endfirsthead

		Parameter& & Description\\
		\hline
		\endhead

		%\hline
		\endfoot

		\endlastfoot

		%\hline
		\multicolumn{2}{l}{Females} & Female natural mortality and growth parameters in the following order by GP\\
		& natM & Natural mortality for female GP1, where the number of natural mortality parameters depends on the option selected.\\
		& Lmin & Length at Amin (units in cm) for female, GP1 \\
		& Lmax & Length at Amax (units in cm) for female, GP1 \\
		& VBK & Von Bertanlaffy growth coefficient (units are per year) for females, GP1\\
		\hline
		\multicolumn{2}{l}{COND if growth type =2 } & \\
		& Richards Coefficient & Only include this parameter if Richards growth function is used.  If included, a parameter value of 1.0 will have a null effect and produce a growth curve identical to Bertalanffy.\\
		\multicolumn{2}{l}{COND if growth type =3 } & Age-Specific K \\
		& \multicolumn{2}{l}{K deviations for first age in rage}\\
		& \multicolumn{2}{l}{K deviations for next age in rage}\\
		& ... & \\
		& \multicolumn{2}{l}{K deviations for last age in rage}\\
		\hline
	    & CV young & Variability for size at age <= AFIX (units are fraction) for females, GP1.  Note that CV cannot vary over time, so do not set up env-link or a dev vector.  Also, units are either as CV or as standard deviation, depending on assigned value of CV pattern.\\
		& CV old & Variability for size at age >= AFIX (units are fraction) for females, GP1. For intermediate ages, do a linear interpolation of CV on means size-at-age.  Note that the units for CV will depend on the CV pattern and the value of MGparm as offset.\\
		\hline
		\multicolumn{2}{l}{COND: GP > 1} & Repeat female parameters in the above order for GP2\\
		\hline
		\multicolumn{2}{l}{Males} & Male natural mortality and growth parameters in the following order by GP\\
		& natM & Natural mortality for male GP1, where the number of natural mortality parameters depends on the option selected.\\
		& Lmin & Length at Amin (units in cm) for male, GP1\\
		& Lmax & Length at Amax (units in cm) for male, GP1\ \\
		& VBK &  Von Bertanlaffy growth coefficient (units are per year) for males, GP1\\
		\hline
		\multicolumn{2}{l}{COND if growth type =2 } & \\
		& Richards Coefficient & Only include this parameter if Richards growth function is used.  If included, a parameter value of 1.0 will have a null effect and produce a growth curve identical to Bertalanffy.\\
		\multicolumn{2}{l}{COND if growth type =3 } & Age-Specific K \\
		& \multicolumn{2}{l}{K deviations for first age in rage}\\
		& \multicolumn{2}{l}{K deviations for next age in rage}\\
		& ... & \\
		& \multicolumn{2}{l}{K deviations for last age in rage}\\
		\hline
		& CV young & Variability for size at age <= AFIX (units are fraction) for males, GP1.  Note that CV cannot vary over time, so do not set up env-link or a dev vector.  Also, units are either as CV or as standard deviation, depending on assigned value of CV pattern.\\
		& CV old &  Variability for size at age >= AFIX (units are fraction) for males, GP1. For intermediate ages, do a linear interpolation of CV on means size-at-age.  Note that the units for CV will depend on the CV pattern and the value of MGparm as offset.\\
		\multicolumn{2}{l}{COND: GP > 1} & Repeat male parameters in the above order for GP2\\
		\hline
		\multicolumn{2}{l}{Females} & Weight length relationship parameters, maturity and fecundity\\
		& WtLen scale & Coefficient to convert length in cm to weight in kg for females\\
		& WtLen exp & Exponent in to convert length to weight for females\\
		& Mat-50 & Maturity logistic inflection (in cm or years).  Where female maturity-at-length (or age) is a logistic function: $maturity = 1/(1+exp(slope*(size-at-age - inflection)))$\\
		& Mat-slope & Logistic slope (must have negative value) \\
		& Eggs-alpha & Two fecundity parameters; usage depends on the selected fecundity option.  Must be included here eve if vector is read in the control section above.\\
		& Eggs-beta & \\
		\hline
		\multicolumn{2}{l}{COND: GP > 1} & Repeat female parameters in the above order for GP2\\
		\hline
		\multicolumn{2}{l}{Males} & Weight length relationship parameters\\
		& WtLen scale & Coefficient to convert length in cm to weight in kg for males\\
	    & WtLen exp & Exponent in to convert length to weight for males\\
		\hline
		\multicolumn{2}{l}{COND: GP > 1} & Repeat male parameters in the above order for GP2\\
		\hline
		\multicolumn{2}{l}{COND: Hermaphrodism} & 3 parameters define a normal distribution for the transition rate of females to males\\
		& Inflect Age & Hermaphrodite inflection age\\
		& StDev & Hermaphrodite standard deviation (in age) \\
		& Asmp Rate & Hermaphrodite asymptotic rate\\
		\hline
		\multicolumn{2}{l}{Recr Dist GP} & Recruitment apportionment by GP, if multiple GP, multiple entries required\\
		\multicolumn{2}{l}{Recr Dist Area} & Recruitment apportionment by area, if multiple areas, multiple entries required\\
		\multicolumn{2}{l}{Recr Dist Seas} & Recruitment apportionment by season, if multiple seasons, multiple entries required\\
		\hline
		\multicolumn{2}{l}{COND:} & If recruitment distribution interaction = 1 (on)\\
		& N patterns x N areas x N seasons & Note that the order of recruitment distribution parameters has areas then seasons for main effect, and seasons then areas for interactions.\\
		\hline
		\multicolumn{2}{l}{Cohort growth deviation} & If no deviations the INIT set equal to 1\\
		\multicolumn{2}{l}{2 x N selected movement pairs} & Movement parameters\\
		\hline
		\multicolumn{2}{l}{COND:} & The following lines are only required when the associated features are turned on\\
		& Ageing Error & Turned on in the data file\\
		& Catch Multiplier & Turned on in the data file\\
		\hline
		\multicolumn{2}{l}{Fraction female} & Fraction female by GP, if multiple GP, multiple entries required\\
		\hline
	\end{longtable}
\end{center}

Example format for MG parameter section:
\begin{center}

	\begin{longtable}{p{1cm} p{1cm} p{1cm}  p{1.5cm}  p{1.5cm}  p{1.5cm}  p{5cm}  }
		\hline
		%LO & HI & INIT & Prior Value &  <other entries> & Block type & Parameter Label \\
		 &  &  & Prior &  <other & Block &  \\
		LO & HI & INIT & Value &  entries> & Type & Parameter Label \\
		\hline
		\endfirsthead

		\hline
		&  &  & Prior &  <other & Block &  \\
		LO & HI & INIT & Value &  entries> & Type & Parameter Label \\
		\hline
		\endhead

		%\hline
		\endfoot

		\endlastfoot

		%\hline
		0    & 0.50 & 0.15 & 0.1  & ... & 0 & \#NatM\_p\_1\_Fem\_GP\_1\\
		0    & 45   & 21   & 36   & ... & 0 & \#L\_at\_Amin\_Fem\_GP\_1 \\
		40   & 90   & 70   & 70   & ... & 0 & \#L\_at\_Amax\_Fem\_GP\_1 \\
		0    & 0.25 & 0.15 & 0.10 & ... & 0 & \#VonBert\_K\_Fem\_GP\_1 \\
		0.10 & 0.25 & 0.15 & 0.20 & ... & 0 & \#CV\_young\_Fem\_GP\_1 \\
		0.10 & 0.25 & 0.15 & 0.20 & ... & 0 & \#CV\_old\_Fem\_GP\_1 \\
		-3   & 3    & 2e-6 & 0    & ... & 0 & \#Wtlen\_1\_Fem \\
		-3   & 4    & 3    & 3    & ... & 0 & \#Wtlen\_2\_Fem \\
		50   & 60   & 55   & 55   & ... & 0 & \#Mat50\%\_Fem  \\
		-3   & 3    & -0.2 & -0.2 & ... & 0 & \#Mat\_slope\_Fem \\
		-5   & 5    & 0    & 0    & ... & 0 & \#Eggs/kg\_inter\_Fem \\
		-50  & 5    & 0    & 0    & ... & 0 & \#Eggs/kg\_slope\_wt\_Fem \\
		0    & 0.50 & 0.15 & 0.1  & ... & 0 & \#NatM\_p\_1\_Mal\_GP\_1\\
		0    & 45   & 21   & 36   & ... & 0 & \#L\_at\_Amin\_Mal\_GP\_1 \\
		40   & 90   & 70   & 70   & ... & 0 & \#L\_at\_Amax\_Mal\_GP\_1 \\
		0    & 0.25 & 0.15 & 0.10 & ... & 0 & \#VonBert\_K\_Mal\_GP\_1 \\
		0.10 & 0.25 & 0.15 & 0.20 & ... & 0 & \#CV\_young\_Mal\_GP\_1 \\
		0.10 & 0.25 & 0.15 & 0.20 & ... & 0 & \#CV\_old\_Mal\_GP\_1 \\
		-3   & 3    & 2e-6 & 0    & ... & 0 & \#Wtlen\_1\_Mal \\
		-3   & 4    & 3    & 3    & ... & 0 & \#Wtlen\_2\_Mal \\
		0.001 & 0.999 & 0.5 & 0.5 & ... & 0 & \#FracFemale\_GP\_1 \\
		\hline
	\end{longtable}
\end{center}

\subsubsection{Natural Mortality Notes}
The options for natural mortality have been expanded.  In addition, M is now, in most options, calculated according to real age since the beginning of a cohort’s birth season, rather than annual, integer age.  So, if M varies by age, M will change by season and cohorts born in early seasons of the year will have different M than late born cohorts.

\hypertarget{Lorenzen}{}
\begin{description}
	\item[Lorenzen Natural Mortality]\hfil\\
	Lorenzen natural mortality is based on the concept that natural mortality varies over the life cycle of a fish, which is driven by physiological and ecological processes.
\end{description}

\subsubsection{Growth Notes}
\hypertarget{A1}{}
When fish recruit at the real age of 0.0 at the beginning of their birth season, they have body size equal to the lower edge of the first population size bin.  Previously, they recruited at a size equal to the lower edge of the smallest data size bin.  The fish then grow linearly until they reach a real age equal to the input value “growth\textunderscore age\textunderscore for\textunderscore L1” and have a size equal to the parameter value for L1.  As they age further, they grow according the Bertalanffy growth equation.  The growth curve is calibrated to go through the size L2 when they reach the age “Growth\textunderscore age\textunderscore for\textunderscore L2”.

If “Growth\textunderscore age\textunderscore for\textunderscore L2” is set equal to 999, then the size L2 is used as Linf.  If MGparm\textunderscore def option ==1 (direct estimate, not offsets), then setting a male growth or natural mortality parameter value to 0.0 and not estimating it will cause SS to use the corresponding female parameter value for the males. This check is done on a parameter, by parameter basis and is probably most useful for setting male L1 equal to female L1, then letting males and females have separate K and Linf parameters.

\begin{description}
	\item[Schnute growth function]\hfil\\
	The Schnute implementation of a 3-parameter growth function is invoked by entering 2 in the grow\textunderscore type field.  Then a fourth parameter is read after reading the von Bertalanffy K parameter.  When this fourth parameter has a value of 1.0, it is equivalent to the standard von Bertalanffy growth curve.  When this function was first introduced in SS, it required that A0 be set to 0.0.
	\item[Age-specific K]\hfil\\
	A new growth option, \#3, has been introduced in V3.23.  This option creates age-specific K deviations for each age of a user-specified age range, with independent additive deviations for each age in the range and for each growth pattern / gender.  Each of these deviations is entered as a full parameter line, so inherits all time-varying capabilities of full parameters.  The lower end of this age range cannot extend younger than the specified age for which the first growth parameter applies.  This is a beta model feature, so examine output closely to assure you are getting the size-at-age pattern you expect.  Beware of using this option in a model with seasons within year because the K deviations are indexed solely by integer age according to birth year.  There is no offset for birth season timing effects, nor is there any seasonal interpolation of the age-varying K.
\end{description}

\subsubsection{Growth Patterns (morphs) and Sub-Morphs}
The user specifies a number of growth patterns (usually just 1), a number of genders (usually 2), and a number of birth seasons.  The collection of Bio\textunderscore pattern x Gender x BirthSeas constitute the “morphs”.  The number of sub-morphs per morph can be 1, 3, or 5.  The fraction of recruits that are female is specified as an input value (not a parameter), and the fraction of recruits assigned to each sub-morph is custom-input or designated to be a normal approximation.  When multiple sub-morphs are designated, an additional input is the ratio of between sub-morph to within sub-morph variability in size-at-age.  This is used to partition the total growth variability.  Growth parameters are read for each growth pattern x gender combination.  For the sub-morphs, their size-at-age is calculated as a factor (determined from the between-within variability calculation) times the size-at-age of the central morph which is determined from the growth parameters for the growth pattern x gender.

\subsubsection{Recruitment, Age, and Growth}
Recruitment can occur in any season.  In older versions of SS one value of spawning biomass was calculated annually at the beginning of one specified spawning season and this spawning biomass produces one annual total recruitment value and this annual recruitment was distributed among seasons, areas, and growth types according to other model parameters.  SSv3.3 allows for the spawning biomass in a season to produce recruitment that may vary over the year based on the spawning biomass which associated with the area and growth types according to the model parameterization. These distribution parameters can be time-varying, so the fraction of the recruits that occur in a particular season can change from year to year. For the recruitment apportionment, the parameter values are the ln(apportionment weight), so should have values ranging from about –4 to +4.  The product of all apportionment weights is calculated for each pattern x area x season cell that has been designated to receive recruits in the recruitment design matrix.  Then the apportionment weights are scaled to sum to 1.0 (within year, not within season) so that the total annual recruitment is distributed among the cells designated to receive recruitment.

In a seasonal model, all cohorts graduate to the age of 1 when they first reach January 1, even if the seasonal structure of the model has them being born in the fall.  In general, this means that SS operates under the assumption that all age data have been adjusted so that fish graduate to the next age on Jan 1.  This can be problematic if the ageing structures deposit a ring at another time of year.  Consequently, you may need to add or subtract a year to some of your age data to make it conform to the SS structure, or you may need to define the SS calendar year to start at the beginning of the season at which ring deposition occurs.  Talk with your ageing lab about their criteria for seasonal ring deposition!

Seasonal recruitment is coded to work smoothly with growth.  If the recruitment occurring in each season is assigned the same growth pattern, then each seasonal cohort’s growth trajectory is simply shifted along the age/time axis.  At the end of the year, the early born cohorts will be larger, but all are growing with the same growth parameters so all will converge in size as they approach their common Lmax.

Age 0.0 fish (at beginning of their birth season) are assigned a size equal to the lower edge of the first population size bin and they grow linearly until they reach the age A1.  SS generates a warning if the first population length bin is greater than 10 cm as this seems an unreasonably large value for a larval fish.  A1 is in terms of real age elapsed since birth.  All fish advance to the next integer age on Jan 1, regardless of birth season.  For example, consider a 2 season model with some recruitment in each season and with each season’s recruits coming from the same GP.  At the end of the first year, the early born fish will be larger but both of the seasonal cohorts will advance to an integer age of 1 on Jan 1 of the next year.  The full growth curve is still calculated below A1, but the size-at-age used by SS is the linear replacement.  Because the linear growth trajectory can never go negative, there is no need for the additive constant to the stddev (necessary for the growth model used in SS2 V1.x), but the option to add a constant has been retained in the model.

\subsubsection{Cohort Growth Deviation}
This parameter must be given a value of 1.0 and be given a negative phase so it is not estimated.  Its importance is in serving as a base for blocks or annual devs, which may be estimated, around this base value of 1.0.

\subsubsection{Movement Parameters}
There are 2 movement parameters per area pair flagged in the movement design matrix as needing estimable movement parameters.  For each, the first parameter is for the movement coefficient for young fish and the second is for old fish (with intermediate ramp calculated using the designated start age and end age.  Parameter values are the ln(movement coefficient).  For fish that stay in their source area (e.g. move from area 1 to area 1 in season 1), they are given a movement coefficient of ln(1)=0, but this default value is replaced if the stay movement is selected as needed parameters.  For each source area, each movement coefficient is exponentiated and then they are scaled to sum to 1.0.  At least one needs to not be estimated so that all others are estimated relative to it.

The movement model has been augmented to define movement parameters for each growth pattern.  With this capability, it will be possible to have homing of a growth pattern back to its natal area.

An added feature is the reading of migr\textunderscore firstage immediately after reading the do\textunderscore migration flag if the do\textunderscore migration flag is positive.  This value is a real number, not an integer, to allow for an in-year start to movement in a multi-season model.  The value is the real age at the beginning of a season, even though movement does not occur until the end of the season.  For example, in a  setup with two 6-month seasons:  a value of 0.5 will cause the age 0 fish to not move when they complete their first 6 month season of life, and then to move at the end of their second season because they start movement capability when they reach the age of 0.5 years (6 months).

A new feature added in v3.3 allows for a multi-season setup to have a growth pattern (GP) to have some fish recruit in different “birthseasons”.  The movement parameters are now specific to GP x birthseason x actual season.

Future Need:  augment the capability further to allow sex-specific movement, and also to allow some sort of mirroring so that genders and growth patterns can share the same movement parameters if desired.

The model will allow movement only between source-destination pairs that have an explicit movement definition.  For fish that stay in an area, there are two options:
\begin{enumerate}
	\item define an explicit movement pattern where the destination area is the same as the source area.  This will allow you to control its parameters explicitly;
	\item allow the model to create an implicit stay rate definition equivalent to setting the movement strength parameter to 0 for all ages.
\end{enumerate}

For all explicit definitions requested, there must be 2 parameters included with the MG parameter section.  As before, the age-specific movement strength is:
\begin{enumerate}
	\item constant at P1 below minage, constant at P2 above maxage, and linearly interpolated for intermediate ages;
	\item exponentiated so that a movement strength parameter value of 0 becomes 1.0;
	\item for movement out of an area, the exponentiated value is multiplied by season duration;
	\item for each source area, all movement rates are then summed and divided by this sum so that 100\% of the fish are accounted for in the movement calculations;
	\item it is best if at least one of the destinations for each source area has a predefined movement strength so that other destinations are estimated relative to the fixed value.
\end{enumerate}

\subsubsection{Recruitment Allocation and Movement Parameters}
In a 2 season, 2 area, 2 growth pattern set-up, the recruitment distribution, cohort growth deviation, and movement parameters could be:

\begin{center}
	\begin{longtable}{ p{0.7cm} p{0.7cm} p{0.7cm}  p{1cm}  p{1.1cm}  p{1cm}  p{8cm}  }
		\hline
		%LO & HI & INIT & Prior Value &  <other entries> & Block type & Parameter Label \\
		&  &  & Prior &  <other & Block &  \\
		LO & HI & INIT & Value &  entries> & Type & Parameter Label \\
		\hline
		\endfirsthead

		\hline
		&  &  & Prior &  <other & Block &  \\
		LO & HI & INIT & Value &  entries> & Type & Parameter Label \\
		\hline
		\endhead

		%\hline
		\endfoot

		\endlastfoot

		%\hline
		-4   & 4    & 0    & 1    & ... & 0 & \#RecrDist\_GP\_1\\
	    -4   & 4    & 0    & 1    & ... & 0 &  \#RecrDist\_GP\_2\\
		-4   & 4    & 0    & 1    & ... & 0 &  \#RecrDist\_Area\_1 \\
		-4   & 4    & -4   & 1    & ... & 0 &  \#RecrDist\_Area\_2 \\
		-4   & 4    & 0    & 1    & ... & 0 &  \#RecrDist\_Seas\_1 \\
		-4   & 4    & -4   & 1    & ... & 0 &  \#RecrDist\_Seas\_2 \\
		-4   & 4    & 0    & 1    & ... & 0 & \#CohortGrowthDev \\
		\multicolumn{7}{l}{COND: Only if movement is defined} \\
		-5   & 5    & -4   & 1    & ... & 0 & \#MoveParm\_A\_seas\_1\_GP\_1from\_1to2 \\
		-5   & 5    & -4   & 1    & ... & 0 & \#MoveParm\_B\_seas\_1\_GP\_1from\_1to2 \\
		-5   & 5    & -4   & 1    & ... & 0 & \#MoveParm\_A\_seas\_1\_GP\_1from\_2to1 \\
		-5   & 5    & -4   & 1    & ... & 0 & \#MoveParm\_B\_seas\_1\_GP\_1from\_2to1 \\
		-5   & 5    & -4   & 1    & ... & 0 & \#MoveParm\_A\_seas\_1\_GP\_2from\_1to2 \\
		-5   & 5    & -4   & 1    & ... & 0 & \#MoveParm\_B\_seas\_1\_GP\_2from\_1to2 \\
		-5   & 5    & -4   & 1    & ... & 0 & \#MoveParm\_A\_seas\_1\_GP\_2from\_2to1 \\
		-5   & 5    & -4   & 1    & ... & 0 & \#MoveParm\_B\_seas\_1\_GP\_2from\_2to1 \\
		\hline
	\end{longtable}
\end{center}

\begin{description}
	\item[Note:]\
	\begin{itemize}
		\item For the recruitment parameters, there must be a line for each season, area and GP.  But only those seasons, areas, and GPs designated to receive recruits in the recruitment design matrix will have the parameter used in the recruitment distribution calculation.
		\item For both recruitment allocations and movement rates, SS processes the parameter values according to the following equation:
		\begin{equation}
			rate_i = \frac{e^{p_i}}{\sum_{j=1}^{N}e^{p_i}}
		\end{equation}
		\item Set the value of one of these parameters to 0.0 and not estimate it so that other areas will be estimated relative to that base area.
		\item Be sure that estimated parameters are given a min-max of something like -5 and 5 so they have a good range relative to the base area.
		\item In order to get a different distribution of recruitments in different years, you will need to make at least one of the recruitment distribution parameters time-varying.
	\end{itemize}
\end{description}

\subsubsection{Catch Multiplier}
This  parameter line is only included in the control file if the catch multiplier field in the data file is set to 1.  A single value may be fixed or estimated where:
\begin{equation}
C_{obs} = C_{exp} * c_{mult}
\end{equation}
where $C_{exp}$ is the expected catch and $c_{mult}$ is the catch multiplier. It has year-specific, not season-specific, time-varying capabilities.  In the catch likelihood calculation, expected catch is multiplied by the catch multiplier by year and fishery before being compared to the observed retained catch, so value of 1.1 means that the observed catch has overestimated actual catch by 10\%.

\subsubsection{Ageing Error Parameters}
These 7 parameters are only included in the control file if one of the ageing error definitions in the data file has requested this feature (by putting a negative value for the ageing error of the age zero fish of one ageing error definition.  Although these are input with full parameter lines (with inherent time-varying capability), the time-varying updating has not been implemented.

Until a more complete description and examples are developed, here is the code for creation of the vectors of mean age’ and stddev of age’:
\\\\
\includegraphics{age_error}
\\\\
The 7 parameters are:

	\begin{itemize}
		\item age at which the estimated pattern begins (just linear below this age).  This is “start age”
		\item bias at start age (as additive offset from unbiased age’)
		\item bias at maxage (as additive offset from unbiased age’)
		\item power fxn coefficient for interpolating between those 2 values (value of 0.0 produces linear interpolation in the bias)
		\item stdev at age
		\item stdev at max age
		\item power fxn coefficient for interpolating between those 2 values
	\end{itemize}


\subsubsection{Time-Varying Biology Parameters}
Any of the parameters defined above can be made time-varying through linkage to an environmental data series, through time blocks, or by setting up annual deviations.  The options for making biology and selectivity parameters change over time is detailed in the section labeled Time-Varying Parameters.  After reading the biology parameters above, which will include possible instructions to create environmental link, blocks, or dev vectors, then read the following section.  Note that all inputs in this section are conditional (COND) on entries in the biology parameter section.  So if no biology parameters invoke any time-varying properties, this section is left blank (or completely commented out with \#) except for the line with the input of seasonal factors.

When time-varying growth is used, there are some additional considerations to be aware of:
\begin{itemize}
	\item Growth deviations propagate into the forecast.  The user can select which growth parameters get used during the forecast by setting the end year of the last block.  If the last block ends in the model’s endyr, then the grorth parameters in effect during the forecast will revert to the “no-block” baseline level.  By setting the end year of the last block to end year (endyr) + 1, the model will continue the last block’s growth parameter levels throughout the forecast.
	\item The equilibrium benchmark quantities (MSY, F40\%, etc.) previously used end year (endyr) body size-at-age, which is a disequilibrium vector.  There is a capability to specify a range of years over which to average the size-at-age used in the benchmark calculations.
	\item An addition issue occurred in versions prior to 3.20.  Its description is retained here, but it was resolved with the growth code modification for version 3.20.
	\begin{itemize}
		\item Issue for versions prior to 3.20:  When the growth reference ages have A1>0 and A2<999, the effect of time-varying K has a non-intuitive aspect.  This occurs because the virtual size at age 0.0 and the actual Linf are calculated annually from the current L1, L2 and K parameters.  Because  these calculated quantities are outside the age range {A1, A2}, a reduction in K will cause an increase in the calculated size-at-age 0.0 that year.  So there is a ripple effect as the block’s  growth parameters affect the young cohorts in existence at the time of the change.  The workaround for this is to set A1=0 and A2=999.  However, this may create another incompatibility because the size-at-age 0.0 cannot be allowed to be negative and should not be allowed to be less than the size of the first population length bin.  Therefore, previous use of A1=2 might have implied a virtual size at age 0.0 that was negative (which is ok), but setting A1=0 does not allow the size at age=A1 to be negative.
	\end{itemize}
\end{itemize}

\begin{center}
	\begin{longtable}{p{0.5cm} p{2.5cm} p{11cm}}
		\multicolumn{3}{l}{Control file continued:}\\
		\hline
		Value & &  Description\\
		\hline
		\endfirsthead

		\hline
		Value & &  Description\\
		\hline
		\endhead

		%\hline
		\endfoot
		\endlastfoot

		\multicolumn{2}{l}{COND:} & If any MG parameters use environmental linkage, then read next factor\\
		& 0 & 0:  Do not use custom environmental linkage setup, read just one parameter line \\
		&   & 1:  Use custom environmental linkage, so read one parameter line for each MG parameter that uses linkage\\
		\\
		& <short parameter line(s)> & Read 0, 1 or many short parameter lines as necessary\\
		\hline
		\multicolumn{2}{l}{COND:} & If any MG parameters use blocks then read next factor \\
		& 0 & 0:  Do not use custom block setup, read just one parameter line \\
		&   & 1:  Use custom block setup, so read one parameter line for each MG parameter that uses blocks\\
		\\
		& <short parameter line(s)> & Read 0, 1 or many short parameter lines as necessary\\
		\hline
		\multicolumn{3}{l}{\#Seasonality for selected biology parameters (not a conditional input)}\\
		\multicolumn{2}{l}{0 0 0 0 0 0 0 0 0 0} & Read 10 integers to specify which biology parameters have seasonality:  femwtlen1, femwtlen2, mat1, mat2, fec1, fec2, malewtlen1, malewtlen2, L1, K.  Reading a positive value selects that factor for seasonality (\hyperlink{SeasGrowth}{\textit{click here for more information}})\\
		\hline
		\multicolumn{2}{l}{COND:} & If any factors have seasonality, then read N seasons parameters that define the seasonal offsets from the base parameter value.\\
		& <short parameter line(s)> & Read N seasons short parameter lines for each factor selected for seasonality.
		The parameter values define an exponential offset from the base parameter value.\\
		\hline
		\multicolumn{2}{l}{COND:} & If any MG parameters use annual deviations, then read the phase next. \\
		& -1 & All MG parameters using annual deviations will have the deviations begin estimation in this phase.\\
		\hline
	\end{longtable}
\end{center}

\hypertarget{SeasGrowth}{}
\subsubsection{Notes on Seasonal Biology Parameters}
SS\_v3 begins to introduce seasonal effects on selected biology parameters.  Currently, seasonal option is only available for the four wt-len parameters and for the growth K.  Seasonality is not needed for the maturity and fecundity parameters because spawning is only defined to occur in one season.  Seasonal L1 may be implemented at a later date.  The seasonal parameter values adjust the base parameter value for that season.
\begin{equation}
P'=P*exp(seas\_value)
\end{equation}

\hypertarget{WAA}{}
\subsubsection{Empirical Weight-at-Age (wtatage.ss)}
With version 3.04, SS adds the capability to read empirical body weight at age for the population and each fleet, in lieu of generating these weights internally from the growth parameters, weight-at-length, and size-selectivity.  Selection of this option is done by setting Maturity\_Option = 5.  The values are read from a separate file named, wtatage.ss.  This file is only required to exist if this option is selected.  See section 8.1 for additional information on file formatting for empirical weight-at-age.

\subsubsection{Spawner-Recruitment}
The spawner-recruitment section starts by specification of the functional relationship.  The number of parameters needed by each relationship is stored internally (same approach as is used for the number of parameters for each selectivity relationship).

\begin{center}
	\begin{longtable}{p{1cm} p{3cm} p{11cm}}
		\multicolumn{3}{l}{Control file continued:}\\
		\hline
		Value & Label &  Description\\
		\hline
		\endfirsthead

		\hline
		Value & Label &  Description\\
		\hline
		\endhead

		%\hline
		\endfoot
		\endlastfoot

		3 & Spawner-            & The options are: \\
		  & Recruitment         & 1: null \\
		  & Relationship        & 2:  Ricker (2 parameters) \\
		  &                     & 3:  standard Beverton-Holt (2 parameters) \\
		  &                     & 4:  ignore steepness and no bias adjustment.  Use this in conjunction with very low emphasis on recruitment deviations to get CAGEAN-like unconstrained recruitment estimates. (2 parameters, but only uses the first one.)\\
		  &                     & 5:  Hockey stick (3 parameters) for ln(R0), fraction of virgin SSB at which inflection occurs, and the R level at SSB=0.0.\\
		  &                     & 6:  Beverton-Holt with flat-top beyond Bzero (2 parameters)\\
		  &                     & 7:  Survivorship function (3 parameters).  Suitable for sharks and low fecundity stocks to assure recruits are <= pop production \\
	      &                     & 8:  Sheperd (3 parameters)\\
		\hline
		\\
		\multicolumn{3}{l}{Read the required number of short parameter set-up lines (ex. LO HI INIT PRIOR }\\
		\multicolumn{3}{l}{PR\_Type SD PHASE).  These parameters are:}\\
		\hline
		8.5 & log(R0) & Log of virgin recruitment level \\
		\hline
		0.60 & Steepness  & Steepness of S-R, bound by 0.2 and 1.0 for the Beverton-Holt \\
		\hline
		\multicolumn{2}{l}{COND:} & If SRR = 5, 7, or 8\\
		& 3rd Parameter & Optional depending on which SRR function is used \\
		\hline
		0.60 & sigma-R &  std.dev. of log recruitment;
		This parameter has two related roles.  It penalizes deviations from the spawner-recruitment curve, and it defines the offset between the arithmetic mean spawner-recruitment curve (as calculated from log(R0) and steepness) and the expected geometric mean (which is the basis from which the deviations are calculated.  Thus the value of sigmaR must be selected to approximate the true average recruitment deviation.\\
		\hline
		0 & env-link & environmental linkage coefficient. The recruitment parameters are short parameters, so cannot have the generic block or environmental link options.  Instead, this dedicated env-link is provided.  It is used to create a multiplicative adjustment to the target parameter, so $P_{y’} = P *exp(env/_link * env/_data_y)$.  An alternative that provides an additive link is under development.\\
		\hline
		8.5 & log(R1) & Offset for initial equilibrium recruitment to virgin recruitment.\\
		\hline
		\multicolumn{2}{l}{AutoCorrelation} & Autocorrelation in recruitment \\
		\hline
		\\
		\multicolumn{3}{l}{Then read additional spawner-recruitment conditions:}\\
		\hline
		0 & SR\_env\_link & This is the index of the environmental variable that will be used as the basis for adjustment of SR expectations.  This works for both the forecast period and for the initial equilibrium (by entering a value for the environmental variable one year before the start of the time series).\\
		\hline
		3 & SR\_env\_target & This factor determines what aspect of spawner-recruitment is affected by the environmental variable.  The options are:\\
		& & 1: annual deviations\\
		& & 2: R0 \\
		& & 3: steepness\\
		& & If the application needs to compare the environment to annual recruitment deviations, then the preferred option is to transform the environmental variable into an age 0 pre-recruit survey and enter these as a survey with expected value based on selectivity option \#31.  Use of SR\_env\_target=1 is discouraged because it interacts with the level of residual recruitment variability and there is no implementation of a bias correction for the variability in recruitment caused by the environmental variable.  If the application is investigating regime shifts, then enter an environmental variable with a time series of zeros and ones to describe the regime periods, then use SR\_env\_target of 2 or 3 to adjust the expected level of recruitment according to the regime variable.  Note that MSY related quantities will be calculated with the regime in the zero state only.  However, the forecast can be responsive to designated regime levels.\\
		\hline
		1 & Do\_Recr\_Dev & This selects the way in which recruitment deviations are coded:\\
		  &  & 0:  none (so all recruitments come from S-R curve)\\
		  &  & 1:  dev vector (previously the only option).  Here the deviations are encoded as a dev\_vector, so ADMB enforces a sum-to-zero constraint.\\
		  &  & 2:  simple deviations.  Here the deviations do not have an explicit constraint to sum to zero, although they still should end up having close to a zero sum.  The difference in model performance between options (1) and (2) has not been fully explored to date.\\
		\hline
		1971 & Main recr devs begin year & If begin year is less than the model start year, then the early deviations are used to modify the initial age composition.   However, if set to be more than Nages before start year, it is changed to equal Nages before start year. \\
		\hline
		1999 & Main recr devs end year & If recr devs end year is later than retro year, it is reset to equal retro year. \\
		\hline
		3    & Main recr dev phase & \\
		\hline
		1 & Advanced  & 0: Use default values for advanced options \\
		  & Options  & 1: Read values for the 11 advanced options \\
		\hline
		\multicolumn{3}{l}{COND = 1 Beginning of advanced options}\\
		& 1950 & Early Recruitment Deviation Start Year: \\
		&  & 0: skip (default) \\
		&  & +year:  absolute year (must be less than begin year of main  recr devs)\\
		&  & -integer:  set relative to main recr dev start year\\
		&  & NOTE:  because this is a dev vector, it should be long enough so that recr devs for individual years are not unduly constrained. \\
		& 6 & Early Recruitment Deviation Phase: \\
		& & Users may want to set to a late phase if there is not much early data; Default:  -4\\
		& 0 & Forecast Recruitment Phase: \\
		& & Forecast recruitment deviations always begin in the first year after the end of the main recruitment deviations.  Setting their phase to 0 causes their phase to be set to max lambda phase +1 (so that they become active after rest of parameters have converged.).  However, it is possible here to set an earlier phase for their estimation, or to set a negative phase to keep the forecast recruitment devs at a constant level. Default:  0 \\
		& 1 & Forecast Recruitment Deviations Lambda:\\
		&   & This lambda is for the logL of the forecast recruitment devs that occur before endyr+1.  Use a larger value here if solitary, noisy data at end of time series cause unruly recr dev estimation. Default:  1.0 \\
		& 1956 & Last Year With No Bias Adjustment \\
		& 1970 & First Year With Full Bias Adjustment \\
		& 2001 & Last Year With Full Bias Adjustment \\
		& 2002 & First Recent Year With No Bias Adjustment \\
		&      & These four entries control how the bias adjustment is phased in and then phased back out when the model is searching for the maximum logL.  Bias adjustment is automatically turned off when in MCMC mode.  For intervening years between the first and second years in this list, the amount of bias adjustment that will be applied is linearly phased in.  The first year with full bias adjustment should be a few years into the data-rich period so that SS will apply the full bias-correction only to those recruitment deviations that have enough data to inform the model about the full range of recruitment variability.  See the recruitment advisory for more information.
		Defaults for the four year values: Start year – 1000, Start year – Nages, Main recr dev final year, End year +1.\\
		& 0.85 & Max Bias Adjustment: \\
		&      & Value for the maximum bias adjustment during the MLE mode.  Use value of 1.0 for compatibility with previous versions of SS.  All estimated recrdevs, even those within a ramped era, switch to maxbias=1.0 during MCMC.\\
		& 0    & Period For Recruitment Cycles: \\
		&      & Use this when SS is configured to model seasons as years and there is a need to impose a periodicity to the expected recruitment level.  If value is >0, then read that number of full parameter lines below define the recruitment cycle \\
		& -5   & Minimum Recruitment Deviation: Min value for recruitment deviation. Default: -5\\
		& 5    & Maximum Recruitment Deviation: Max value for recruitment deviation. Default: 5\\
		& 2    & Number of Explicit Recruitment Deviations to Read:\\
		&      & 0: Do not read any recruitment deviations; Integer: read this number of recruitment deviations; Default:  0 \\
		\multicolumn{3}{l}{END OF ADVANCED OPTIONS}\\
		\hline
		\multicolumn{3}{l}{COND = Enter N full parameter lines below if N recruitment cycles is > 0}\\
		& <parameter line> & Full parameter line for each of the N periods of recruitment cycle\\
		\hline
		\multicolumn{3}{l}{COND = If N explicit recruitment deviations is > 0, then enter N lines below}\\
		& 1977 3.0 & Enter Year and Deviation\\
		& 1984 3.0 & Two example recruitment deviations being read.  NOTE:  SS will rescale the entire vector of recrdevs after reading these deviations, so by reading two positive values, all other recrdevs will be scaled to a small negative value to achieve a sum to zero condition before starting model estimation\\
		\hline
	\end{longtable}
\end{center}

\subsubsection{Spawner-Recruitment Function}
The number of age-0 fish is related to spawning biomass according to a stock-recruitment relationship.  SS has the option of the Beverton-Holt, Ricker, Hockey-Stick, and a survival-based stock recruitment relationship.

\begin{description}
	\item[Beverton-Holt]\hfil\\
	The Beverton-Holt Stock Recruitment curve is calculated as:
	\begin{equation}{R_y = \frac{4hR_0SB_y}{SB_0(1-h)+SB_y(5h-1)}e^{-0.5b_y\sigma^2_R+\tilde{R}_y}\qquad  \tilde{R}_y\sim N(0;\sigma^2_R)}
	\end{equation}
	where $R0$ is the unfished equilibrium recruitment, $SB0$ is the unfished equilibrium spawning biomass (corresponding to R0), SBy is the spawning biomass at the start of the spawning season during year y, h is the steepness parameter, by is the bias adjustment fraction applied during year y,   is the standard deviation among recruitment deviations in log space, and   is the lognormal recruitment deviation for year y.  The bias-adjustment factor (Methot and Taylor 2011) ensures unbiased estimation of mean recruitment even during data-poor eras in which the maximum likelihood estimate of the   is near 0.0.

	\item[Ricker]\hfil\\
	The Ricker Stock Recruitment curve is calculated as:
	\begin{equation}{R_y = \frac{R_0SB_y}{SB_0}e^{h(1-SB_y/SB_0)}e^{-0.5b_y\sigma^2_R+\tilde{R}_y}\qquad  \tilde{R}_y\sim N(0;\sigma^2_R)}
	\end{equation}

	\item[Hockey-Stick]\hfil\\
	The hockey-stick recruitment curve is calculated as:
	\begin{equation}{R_y = R_{min}R_0+\frac{SB_y}{hSB_0}(R_0-R_{min})(join)+R_0(1-join) }\end{equation}
	where $R_{min}$ is the minimum recruitment level predicted at a spawning size of zero and is set by the user in the control file, h is defined as the fraction of $SB0$ below which recruitment declines linearly, and $join$ is defined as:
	\begin{equation}{ join = \bigg[1+e^{1000*\frac{(SB_0-hSB_0)}{SB_0}}\bigg]^{-1} } \end{equation}

	\item[Survivorship]\hfill\\
	Survival-based recruitment (Taylor et al. 2012) is constrained so that the recruitment rate cannot exceed fecundity:
	\begin{equation}{ R_y = e^{\Big(-z_0 + (z_0-z_{min})\big(1-(SB_y/SB_0)^\rho \big)\Big)}\qquad  \tilde{R}_y\sim N(0;\sigma^2_R)}
	\end{equation}
	where $z_0$ (P) is the negative log of the pre-recruit mortality rate at unfished equilibrium, $z_{min}$ is the limit of the pre-recruit mortality as relative spawning biomass approaches 0, parameterized as a function of $z_{frac}$ (P) (which represents the reduction in mortality as a fraction of $z_0$), and $\rho$ (P) is a parameter controlling the shape of density-dependent relationship between relative spawning biomass and pre-recruit survival. The steepness (h) of the spawner-recruit curve (defined as recruitment relative to R0 at a spawning depletion level of 0.2) is:\\
	\begin{equation}
		h = 0.2e^{z_0z_{frac}(1-0.2^\beta)}
	\end{equation}
	This 3-parameter function was created for use with low fecundity species, but its use of 3-parameters provides a flexibility comparable to the 3-parameter Shepherd function.  This survival based spawner-recruitment function defines survival from the egg (e.g. hatched pups) to the recruits stage to be a declining function of the initial number of pups produced (Taylor et al. 2012).
	\begin{itemize}
		\item Start with the parameter, ln(R\_0), which is the ln(mean number of recruits) that enter the population in unfished conditions.
		\item These recruits over their lifetime will produce some total number of eggs (pups), termed Pups\_0, which can be calculated from natural mortality, which defines the numbers at age in the adult population, and fecundity at age.
		\item Because the unfished condition is considered to be a stable equilibrium, we can calculate PPR\_0 = Pups\_0/R\_0 and its inverse which is survivorship, which we will define in logarithmic space.  So, Z\_0 = ln(R\_0/Pups\_0).  Note that there is no explicit time over which this Z acts.  Such an explicit time (e.g. the age ar recruitment) may be implemented in the future.  For now, this means that the Z is really a Z*delta t.
		\item So, Z\_0 is the survival when the population is at carrying capacity.  On the other extreme, the maximum survival is 1.0, so the maximum Z is 0.0.
		\item The parameter, S\_frac, defines the level of Z when the population approaches an abundance of 0.0.  This has values bounded by 0.0 and 1.0 and creates a Z\_max which is between Z\_0 and 0.0. Z\_max = Z\_0 + S\_frac*(0.0-Z\_0)
		\item Then for the current level of pup production (e.g. total population fecundity, aka “spawning biomass”):
		\begin{itemize}
			\item $Z_y=(1 - (Pup_y/Pups\_0)Beta)*(Z\_max-Z\_0)+Z\_0$
			\item So $R_y = Pupy * exp(-Z_y)$
			\item Where beta is the third parameter and which logically has values between about 0.4 for a left-shifted spawner-recruitment curve, and 3.0 for a right-shifted curve.
		\end{itemize}
		\item With the other spawner-recruitment relationships, the mean level of recruits, $R_y$ , serves as the base against which environmental effects and annual lognormal deviations are applied.  However, in a survival context, it is possible that a large positive deviation on recruitments could imply survival greater than 1.0, so an alternative approach is needed for this survival approach.  Here, the lognormal deviations are applied to Z and the resultant S is constrained to not exceed 1.0.
		\item In SS, it is also necessary to be able to calculate the equilibrium level of spawning biomass (pup production) and recruitment for a given level of spawning biomass per recruit (pups per recruit), PPR.
		\begin{itemize}
			\item $Pups\_equil = Pups\_0 * (1 - (LN(1/PPR) - Z\_0)/(Z\_max - Z\_0))^{(1/Beta)} $
			\item Then, $R\_equil = Pups\_equil * exp(-(1 - (Pups\_equil/Pups\_0)^Beta)*(Z\_max-Z\_0)+Z\_0)$
		\end{itemize}
		\item Code for the survival based recruitment is shown below:
	\end{itemize}

	%\includegraphics{survival_1}\\
	%\includegraphics{survival_2}
	%\includegraphics{survival_3}
	\includegraphics{survival_code}

	\item[Shepherd]\hfil\\
	The Shepherd stock recruit curve is calculated as:
	\begin{equation}
		R_y = \bigg(\frac{SB_y}{SB_0}\bigg)\frac{5hR_0SB^c_0(1-0.2^c)}{(1-h_{adj}0.2^c)+(5h_{adj}-1)SB^c_y}e^{-0.5b_y\sigma^2_R+\tilde{R}_y}\qquad \tilde{R}_y\sim N(0;\sigma^2_R)
	\end{equation}
	where c is the shape parameter for the stock recruitment curve, and $h_{adj}$ is the transformed steepness parameter defined as:
	\begin{equation}
		h_{adj}=\frac{\big(0.2+(h-0.2)\big)\big(1-0.2(5-0.2^c)\big)}{4*0.2^c}
	\end{equation}
\end{description}

\subsubsection{Recruitment Eras}
Conceptually, SS treats the early, data-poor period, the main data-rich period, and the recent/forecast time period as three eras along a continuum.  The user has control of the break year between eras.  Each era has its own vector.  The early era is defined as a vector (prior to V3.10 this was a dev\_vector) so it can have zeros during the earliest years not informed by data and then a few years with non-zero values without imposing a zero-centering on this collection of deviations.  The main era can be a vector of simple deviations, or a dev\_vector but it is normally implemented as a dev\_vector so that the spawner-recruitment function is its central tendency.  The last era does not force a zero-centered deviation vector so it can have zeros during the actual forecast and non-zero values in last few years of the time series.  The early and last eras are optional, but their use can help prevent SS from balancing a preponderance of negative deviations in early years against a preponderance of positive deviations in later years.  When the 3 eras are used, it would be typically to turn on the main era during an early model phase, turn on the early era during a later phase, then have the last era turn on in the final phase.

\subsubsection{Recruitment Likelihood}
In SS2, recruitment log(L) contained a term, + N\_forecast\_rec\_devs*log(sigmaR).  This meant that the total log(L) changed according to how many forecast years were included in the model scenario.  Worse, if sigmaR was allowed to be estimated by SS2, then this term would cause all the zero deviations during the forecast period to drag the overall estimated value of sigmaR down.  This problem is rectified in SS V3.  Now, for each year in the total time series (early, mid, late/forecast) the contribution of that year to the logL is equal to:  dev\^2/(2.0*sigmaR*sigmaR)+offset*log(sigmaR); where offset is the magnitude of the adjustment between the arithmetic and geometric mean of expected recruitment for that year.  With this approach, years with a zero or small offset value do not contribute to the second component.  With this approach, sigmaR may be estimable when there is good data to establish the time series of recruitment deviations.  In the likegfish example, turning on estimate of sigmaR results in an estimated value that is very close to the root mean squared error (rmse) of the estimated recruitment deviations.

\subsubsection{Recruitment Bias Adjustment}
The recruitment bias adjustment implemented in SS is based upon the work being documented in Methot and Taylor (2011) and following the work of Maunder and Deriso (2003).  The concept is based upon the following logic.  SigmaR represents the true variability of recruitment in the population.  It provides the constraining penalty for the estimates of recruitment deviations and it is not affected by data.  Where data that are informative about recruitment deviations are available, the total variability in recruitment, sigmaR, is partitioned into a signal (the variability among the recruitment estimates) and the residual, the variance of each recruitment estimate (see eq. below).  Where there are no data, no signal can be estimated and the individual recruitment deviations collapse towards 0.0 and the variance of each recruitment deviation approaches sigmaR.  Conversely, where there highly informative data about the recruitment deviations, then the variability among the estimated recruitment deviations will approach sigmaR and the variance of each recruitment deviation will approach zero.  Perfect data will estimate the recruitment time series signal perfectly.  Of course, we never have perfect data so we should always expect the estimated signal (variability among the recruitment deviations) to be less than the true population recruitment variability.
\begin{equation}
	SE(\hat{r}_y)^2 + SD(\hat{r})^2=\Bigg( \bigg( \frac{1}{\sigma^2_d}+\frac{1}{\sigma^2_R}\bigg)^{-1/2}\Bigg)^2+\Bigg( \frac{\sigma^2_R}{(\sigma^2_R+\sigma^2_d)^{1/2}}\Bigg)^2=\sigma^2_R
\end{equation}

The correct offset (bias adjustment) to apply to the expected value for recruitment is based on the concept that a time series of estimated recruitments should be mean unbiased, not median unbiased, because the biomass of a stock depends upon the cumulative number of recruits, which is dominated by the large recruitments.  The degree of offset depends upon the degree of recruitment signal that can be estimated.  Where no recruitment signal can be estimated, the median recruitment is the same as the mean recruitment, so no offset is applied.  Where lognormal recruitment signal can be estimated, the mean recruitment will be greater than the median recruitment.  The value

\begin{equation}
	b_y=\frac{E\Big( SD(\hat{r}_y)\Big)^2}{\sigma^2_R}=1-\frac{SE(\hat{r}_y)^2}{\sigma^2_R}
\end{equation}

\noindent of the offset then depends upon the partitioning of sigmaR into between and within recruitment variability.  The most appropriate degree of bias adjustment can be approximated from the relationship among sigmaR, recruitment variability (the signal), and recruitment residual error.

\begin{center}
	\includegraphics{10_bias}
\end{center}

Because the quantity and quality of data varies during a time series, SS allows the user to control the rate at which the offset is ramped in during the early, data-poor years, and then ramped back to zero for the forecast years.
On output to report.sso, SS calculates the mean bias adjustment during the early and main eras and compares it to the rmse of estimated recruitment devs.  A warning is generated if the rmse is small and the bias adjustment is larger than 2.0 times the ratio of $rmse^2$ to $sigmaR^2$.

In MCMC mode, the model still draws recruitment deviations from the lognormal distribution, so the full offset is used such that the expected mean recruitment from this lognormal distribution will stay equal to the mean from the spawner-recruitment curve. When SS reaches the MCMC and MCEVAL phases, all biasadj values are set to 1.0 for all active recruitment deviations because the model is now re-sampling from the full lognormal distribution of each recruitment.

\subsubsection{Recruitment Autocorrelation}
The autocorrelation parameter is implemented.  It is not performance tested and it has no effect on the calculation of the offsets described in the section above.

\subsubsection{Recruitment Cycle}
When SS is configured such that seasons are modeled as years, the concept of season within year disappears.  However, there may be reason to still want to model a repeating pattern in expected recruitment to track an actual seasonal cycle in recruitment.  If the recruitment cycle factor is set to a positive integer, this value is interpreted as the number of time units in the cycle and this number of full parameter lines will be read.  The cyclic effect is modeled as an exp(p) factor times R0, so a parameter value of 0.0 has nil effect.  In order to maintain the same number of total recruits over the duration of the cycle, a penalty is introduced so that the cumulative effect of the cycle produces the same number of recruits as Ncycles * R0.  Because the cyclic factor operates as an exponential, this penalty is different than a penalty that would cause the sum of the cyclic factors to be 0.0.  This is done by adding a penalty to the parameter likelihood, where:
\begin{equation}
	\begin{split}
				   X & = \sum(e^p)  \\
				   Y & = Ncycle  \\
				   Penalty & = 100000*(X-Y)^2
	\end{split}
\end{equation}

\subsubsection{Initial Age Composition}
A non-equilibrium initial age composition is achieved by setting the first year of the recruitment deviations before the model start year.  These pre-start year recruitment deviations will be applied to the initial equilibrium age composition to adjust this composition before starting the time series.  The model first applies the initial F level to an equilibrium age composition to get a preliminary N-at-age vector, then it applies the recruitment deviations for the specified number of younger ages in this vector.  If the number of estimated ages in the initial age composition is less than Nages, then the older ages will retain their equilibrium levels.  Because the older ages in the initial age composition will have progressively less information from which to estimate their true deviation, the start of the bias adjustment should be set accordingly.

\subsubsection{Fishing Mortality Method}
There are now three methods available for calculation of fishing mortality.  These are:  Pope’s approximation, continuous F with each F as a model parameter, and a hybrid method that does a Pope’s approximation to provide initial values for iterative adjustment of the continuous F values to closely approximate the observed catch.  With the hybrid method, the final values are in terms of continuous F, but do not need to be specified as full parameters.  In a 2 fishery, low F case, it is just as fast as the Pope approx. and produces identical result.  When F is very high, the problem becomes quite stiff for Pope’s and the hybrid method so convergence may slow.  It may still be better to use F option 2 (continuous F as full parameters) in these high F cases.  F as parameter is also preferred for situations where catch is known imprecisely and you are willing to accept a solution in which the final F values do not reproduce the input catch levels exactly.  Option 1 (Pope’s approx) still exists, but my recommendation is to switch to option 3.

\begin{center}
		\begin{longtable}{p{1cm} p{3cm} p{11cm}}
			\multicolumn{3}{l}{Control file continued:}\\
			\hline
			Value &   &  Description\\
			\hline
			\endfirsthead

			\hline
			Value &  &  Description\\
			\hline
			\endhead

			%\hline
			\endfoot
			\endlastfoot

			0.2 & & F ballpark\\
			    & & This value is compared to the sum of the F’s for the specified year.  The sum is over all seasons and areas.  The lambda for the comparison goes down by a factor of 10 each phase and goes to 0.0 in the final phase.\\
		   \hline
			-1990 & & F ballpark year \\
			      & & Negative value disable F ballpark \\
		   \hline
			-3  & & F Method \\
			    & & 1 = Pope's \\
			    & & 2 = Continuous F as a parameter \\
			    & & 3 = Hybrid F \\
		   \hline
		   0.9 & & Maximum F \\
		       & & This maximum is applied within each season and area.   A value of 0.9 is recommended for F method 1, and a value of about 4 is recommended for F method 2 and 3. \\
		   \hline
		   \multicolumn{3}{l}{COND: Depending on the F method} \\
		   \hline
		   \multicolumn{3}{l}{COND = 1: No additional input for Pope's approximation}\\
		   \hline
		   \multicolumn{3}{l}{COND = 2: Continuous F}\\
		   & 0.10 & Starting value for each F.  Initializing value for each F parameter.\\
		   & 1 & Phase for F parameters becoming active.  \\
		   &   & For phases prior to this value,  SS will use the hybrid option and the F values so calculated become the starting values for the F parameters when this phase is reached.\\
		   & 1 & Number of detailed F inputs to read below. \\
		   \hline
		   \multicolumn{3}{l}{COND = 3: Hybrid F}\\
		   & 4 & Number of tuning iterations in hybrid method. A value of 2 or 3 is sufficient with a single fleet and low Fs.  A value of 5 or so may be needed to match the catch near exactly when there are many fleets and high F. \\
		   \hline
		   \multicolumn{3}{l}{If N for F detail is > 0}\\
		   & 1 1980 1 0.20 0.05 4 & fleet, year, season, F, SE, phase - these values override the catch se values in the data file and the overall starting F value and phase read just above.\\
		   \hline
	\end{longtable}
\end{center}

\subsubsection{Initial Fishing Mortality}
Read a short parameter setup line for each fishery.  The parameters are the fishing mortalities for the initial equilibrium.  Do not try to estimate parameters for fisheries with zero initial equilibrium catch.  If there is catch, then give a starting value greater than zero and it generally is best to estimate the parameter in phase 1.

It is possible to use the initial F method to achieve an estimate of the initial equilibrium Z in cases where the initial equilibrium catch is unknown.  To do this:
\begin{itemize}
	\item Include a positive value for the initial equilibrium catch;
	\item Set the lambda for the logL for initial equilibrium catch to a nil value (hence causing SS to ignore the lack of fit to the input catch level;
	\item Allow the initial F parameter to be estimated.  It will be influenced by the early age and size comps which should have some information about the early levels of Z.
\end{itemize}

\subsubsection{Catchability}
For each fishery and survey, enter a row with these 4 entries as described below:

\begin{enumerate}
	\item Do\_Power
	\begin{enumerate}
		\item 0 = skip, so the survey is directly proportional to abundance (typical)
		\item 1 = establish a parameter for non-linearity in survey-abundance linkage
	\end{enumerate}
	\item Do\_Env\_Link
	\begin{enumerate}
		\item 0 = skip, no environmental on Q (typical)
		\item 1 = establish a parameter to create environmental effect on Q, where the integer is the index of the environmental variable to be linked.  The relationship is:  $ ln(q_y) = ln(q_{base}) + Q_{env\_link\_para}*Env\_Value_y$.
	\end{enumerate}
	\item Do\_extra SD
	\begin{enumerate}
		\item 0 = skip (typical)
		\item 1 = estimate a parameter that will contain an additive constant to be added to the input stddev of the survey variability.  This extra SD approach is highly redundant with the older code that provided for iterative input of variance adjustment factors.  The newer code for extra SD estimation is recommended.
	\end{enumerate}
	\item Q Type
	\begin{enumerate}
		\item <0 = mirror the Q from another (lower numbered survey designated by abs(value))
		\item 0 = set Q as a scaling factor such that the estimate is median unbiased.  This is comparable to the old “float” option.  This option is not available if a normal error structure is used.
		\item 2 = establish one parameter that will be the ln(Q).  Note that Q is in log units even if the error structure is normal.
		\item 3 = establish one parameter that will be the base ln(Q) and a set of additional parameters for each year of the survey that will be deviations in ln(Q).  These deviation parameters are full parameters, so each has a prior and variance, so surveys with high uncertainty in their calibration can be given a more diffuse prior to allow a larger deviation.  Because each of these Q deviations is coded as a separate parameter, rather than a member of a deviation vector, the contribution of these deviations to the model’s objective function is captured in the parameter prior section.  However, because there is no inherent constraint that these deviations have a zero sum, a separate log(L) contribution is calculated from the sum of the deviations ($(1+(\sum(devs))^2)^2-1$) and added to the “parm\_dev\_like” component.
		\item 4 = establish one parameter that will be the base ln(Q) and used as the Q for the first survey observation.  Subsequent N-1 parameters for remaining survey observations will be deviations in random walk of ln(Q).  These deviation parameters are otherwise treated identically to those generated by option (3) above, except that the extra contribution for the mean deviation is not calculated.
		\item 5 = This option will calculate the survey Q according to mean unbiased scaling, then assigns this value to the parameter (which must be set up in the control file and be given a negative phase).  Advantage is that the calculated Q can now have a prior.
	\end{enumerate}
\end{enumerate}

So for a setup with 2 fisheries and 2 surveys, the Q setup matrix could be:

\begin{center}
	\begin{longtable}{p{2.75cm} p{2.75cm} p{2.75cm} p{2cm} p{2cm} p{2cm}}

		\hline
		\endfirsthead

		\hline
		\endhead

		\endfoot
		\endlastfoot
	    \#Do\_power   & Env-Var & Extra SD & Q type & Q offset  & Fleet \\
	    (Den\_depend) &         &          &        &           & \\
	    \hline
	    1 & 0 & 1 & 2 & 0 & \#Fishery 1 \\
	    0 & 0 & 1 & 2 & 0 & \#Fishery 2 \\
	    0 & 0 & 0 & 4 & 0 & \#Survey 1 \\
	    0 & 0 & 1 & 2 & 0 & \#Survey 2 \\
	    \hline
	\end{longtable}
\end{center}

\noindent Q types
\begin{itemize}
	\item <0 = mirror another fleet
	\item 0 = float no bias adjustment
	\item 1 = float bias adjustment
	\item 2 = parameter no bias adjustment
	\item 3 = parameter with random deviations
	\item 4 = parameter with random walk
	\item 5 = mean unbiased float assignment to parameter
\end{itemize}

\noindent COND: If any fishery or survey uses random devs or random walk, there is an option to either read detailed input to set up the deviation, or to just read a template.

\begin{center}
	\begin{longtable}{p{2.75cm} p{2.75cm} p{2.75cm} p{2cm} p{2cm} p{2cm}}
		\endfirsthead
				
		\hline
		\#Value & Label & \multicolumn{4}{l}{Label, Description, and Options} \\
		\hline
		\endhead
				
				%\hline
		\endfoot
		\endlastfoot
		
		\hline
		\#Value & Label & \multicolumn{4}{l}{Label, Description, and Options} \\
		\hline
		1 & Random effects & \multicolumn{4}{l}{\multirow{2}{10cm}{0:  read one parameter line and use it as a template to create a time series of parameters for each observation for each fleet/survey that uses random effects.  The output to control.ss\_new will be in detailed format even if the input is not detailed.  Therefore a simple way to create a detailed setup file is to start with a simple template then edit the control.ss\_new file to create a detailed input for subsequent model runs;}}\\
		\\
		\\
		\\
		\\
		\\
		\\
		\\
		&  & \multicolumn{4}{l}{\multirow{2}{8cm}{1:  read a parameter line for each observation of each fleet/survey that uses random effects, thus allowing customization.  If the Q option for a fleet is 3 (random devs), then read one parameter for each observation.  If the Q option is 4, then read (N observations -1) parameters.}}\\
		\\
		\\
		\\
		\\
		\\
		\\
		\hline
	\end{longtable}
\end{center}
	    

\noindent For each positive element in columns for the catchability (Q) setup above, read a short parameter setup line.  The order is: fishery 1 through survey N within power transformation, then within environment link, then within extra standard deviation, then within Q.  If no elements are selected, then there must be no parameter setup lines.

\begin{center}
	\begin{longtable}{p{1.1cm} p{1.1cm} p{1.2cm} p{1.2cm} p{1.5cm} p{1.1cm} p{1.1cm} p{4.8cm}}
		\endfirsthead
		
		\hline
		\#Lo & Hi & Init & Prior & PR\_type & SD & Phase & Label \\
		\hline
		\endhead
		
		\hline
		\endfoot
		\endlastfoot
		
		\multicolumn{8}{l}{The list of parameters to be read from the above setup would be:}\\
		\hline
		\#Lo & Hi & Init & Prior & PR\_type & SD & Phase & Label \\
		\hline
		0  & 3   & 1 & 1 & 0 & 0.10 & 3 & \#Fishery1 power\\
		0  & 0.5 & 0.10 & 0.10 & 0 & 0 & 4 & \#Fishery1 extra SD\\
		0  & 0.5 & 0.10 & 0.10 & 0 & 0 & 4 & \#Fishery2 extra SD\\
		0  & 0.5 & 0.10 & 0.10 & 0 & 0 & 4 & \#Survey2 extra SD\\
		-7 & 5   & 0.50 & 0.50 & -1 & 1 & 4 & \#Fishery1 base Q\\
		-7 & 5   & 0.50 & 0.50 & -1 & 1 & 4 & \#Fishery2 base Q\\
		-7 & 5   & 0.50 & 0.50 & -1 & 1 & 4 & \#Survey1 base Q\\
		0  & 1   & 0 & 0 & 1 & 0.10 & 3 & \#Survey1 Qrandwalk obs2\\
		0  & 1   & 0 & 0 & 1 & 0.10 & 3 & \#Survey1 Qrandwalk obs3\\
		0  & 1   & 0 & 0 & 1 & 0.10 & 3 & \#Survey1 Qrandwalk obs4\\
		... & ... & ... & ... & ... & ... & ... & ... \\
		-7 & 5   & 0.50 & 0.50 & -1 & 1 & 4 & \#Survey3 base Q\\
		\hline
	\end{longtable}
\end{center}

\subsubsection{Selectivity and Discard}
For each fleet and survey, read a definition line for size selectivity and retention.  The four values read from each line are:

\begin{description}
	\item[Pattern]\hfill\\
	Valid length selectivity pattern code.

	\item[Discard]\hfill\\
	(0/1/2/3 or -index)  If value is 1, then program will read 4 retention parameters after reading the specified number of selectivity parameters and all discarded fish are assumed dead.  If the value is 2, then the program will read 4 retention parameters and 4 discard mortality parameters.  If the value is 3, then no additional parameters are read and all fish are assumed discarded and dead. If the value is a negative number, then it will mirror the retention and discard mortality pattern of the lower numbered fleet.

	\item[Male]\hfill\\
	(0/1/2/3/4)  If value is 1, then program will read 4 additional parameters to define the male selectivity relative to the female selectivity.  Anytime the male selectivity is caused to be greater than 1.0; the entire male/female matrix of selectivity values is scaled by the max so that the realized max is 1.0.  Hopefully this does not cause gradient problems.  If the value is 2, then the main selectivity parameters define male selectivity and female selectivity is estimated as an offset from male selectivity.  This alternative is preferable if female selectivity is less than male selectivity.  The option 3 is only available if the selectivity pattern is 1, 20, or 24 and it causes the male selectivity parameters to be offset from the female parameters, rather than the male selectivity being an offset from the female selectivity.

	\item[Special]\hfill\\
	(0/value).  This value is used in different ways depending on the context.  If the selectivity type is to mirror another selectivity type, then put the index of that source fleet or survey here.  It must refer to a lower numbered fleet/survey.  If the selectivity type is 6 (linear segment), then put the number of segments here.  If the selectivity type is 7, then put a 1 here to keep selectivity constant above the mean average size for old fish of morph 1.
\end{description}

For each fleet and survey, read a definition line for age selectivity.  The 4 values to be read are the same as for the size-selectivity.  However, the retention value must be set to 0.

\begin{center}
	\begin{longtable}{p{2cm} p{2cm} p{2cm} p{2cm} p{3cm} }
		\hline
		\multicolumn{5}{l}{\#Example Setup for Size Selectivity Types}\\
		\#Pattern & Discard & Male & Special & Label \\
		\hline
		27 & 0 & 0 & 3 & \#Fishery1\\
		1  & 0 & 0 & 0 & \#Survey1\\
		0  & 0 & 0 & 0 & \#Survey2\\
		\multicolumn{5}{l}{\#Age Selectivity Types}\\
		\hline
		11 & 0 & 0 & 3 & \#Fishery1\\
		11  & 0 & 0 & 0 & \#Survey1\\
		11  & 0 & 0 & 0 & \#Survey2\\
		\hline
	\end{longtable}
\end{center}

\subsubsection{Selectivity Patterns}
The currently defined selectivity patterns, and corresponding required number of parameters, are:

\begin{center}
	\begin{longtable}{p{2cm} p{3cm} p{10cm}}
		\endfirsthead

		\hline
		Pattern & N Parameters & Description \\
		\hline
		\endhead

		%\hline
		\endfoot
		\endlastfoot

		\hline
		\multicolumn{3}{c}{SIZE SELECTIVITY}\\
		Pattern & N Parameters & Description \\
		\hline
		0 & 0 & Selectivity equals 1.0 for all sizes \\
		1 & 2 & Logistic \\
		2 & 8 & Discontinued: Double logistic with defined peak (uses IF joiners). Use pattern \#8 instead.\\
		3 & 6 & Discontinued \\
		4 & 0 & Discontinued: Set size selectivity equal to female fecundity. Use pattern \#30 instead.\\
		5 & 2 & Mirror another selectivity. The two parameters select bin range.\\
		6 & 2 + special value & Non-parametric \\
		7 & 8 & Discontinued: Double logistic with defined peak, uses smooth joiners; special = 1 causes constant selectivity above Linf for morph 1.  Use pattern \#8.\\
		8 & 8 & Double logistic, with defined peak, uses smooth joiners; special=1 causes constant selectivity above Linf for morph 1.  \\
		9 & 6 & Simple double logistic with no defined peak.\\
		15 & 0 & Mirror another selectivity (same as for age selectivity).\\
		22 & 4 & Double normal; similar to CASAL.\\
		23 & 6 & Same as the double normal pattern \#24 except the final selectivity is now directly interpreted as the terminal selectivity value.\\\
		24 & 6 & Double normal with defined initial and final selectivity level – Recommended option.  Test using SELEX-24.xls. \\
		25 & 3 & Exponential-logistic \\
		27 & 3+2*N nodes & Cubic spline\\
		\hline
		\\
		\multicolumn{3}{c}{SPECIAL SELECTIVITY}\\
		Pattern & N Parameters & Description \\
		\hline
		30 & 0 & Sets expected survey abundance equal to spawning biomass (population fecundity). \\
		31 & 0 & Sets expected survey abundance equal to exp(recruitment deviation).  This is useful if environmental data is used as an index of recruitment variability. \\
		32 & 0 & Sets expected survey abundance equal to exp(recruitment deviation ) * SpawnBiomass.  So this is recruitment without density-dependence (for pre-recruit survey) because most ecological logic places the density-dependent stage during the juvenile period following the larval stage that is most sensitive to environmental perturbation.\\
		33 & 0 & Sets expected survey abundance equal to age-0 recruitment.\\
		34 & 0 & Spawning biomass depletion (B/B0).\\
		\hline
	\end{longtable}
\end{center}

\begin{description}
	\item[Notes on Special Selectivity Options:]\hfil
	\begin{itemize}
		\item Do not input any size/age composition data for surveys using pattern 30-33.
		\item The "catchability" coefficient for these selectivity patterns 30-33 have all the general properties of the catchability coefficient for real surveys, e.g. they can be time-varying, use power relationship, etc.
	\end{itemize}
\end{description}

\begin{center}
	\begin{longtable}{p{2cm} p{3cm} p{10cm}}

		\endfirsthead

		\hline
		Pattern & N Parameters & Description \\
		\hline
		\endhead

		%\hline
		\endfoot
		\endlastfoot

		\hline
		\multicolumn{3}{c}{AGE SELECTIVITY}\\
		Pattern & N Parameters & Description \\
		\hline
		10 & 0 & Age selectivity = 1.0 for all ages beginning at age 1.  If it is desired that age-0 fish be selected, then use pattern \#11 and set minimum age to 1.0. \\
		11 & 2 & Pick min-max age\\
		12 & 2 & Logistic\\
		13 & 8 & Double logistic, IF joiners.  Use discouraged.  Use pattern \#18 instead.\\
		14 & nages+1 & Each age, value at age is $\frac{1}{1+exp(-x)}$ \\
		15 & 0 & Mirror another selectivity\\
		16 & 2 & Coleraine single Gaussian\\
		17 & nages + 1 & Each age as random walk from previous age.  For all ages in the population beginning with Amin = 1 for the fishery and 2 for the survey, there is a corresponding set of selectivity parameters for each fleet, $p_a$. \hyperlink{RandWalk}{Click here for more information.}\\
		18 & 8 & Double logistic, with defined peak, uses smooth joiners.  \\
		19 & 6 & Simple double logistic with no defined peak.\\
		20 & 6 & Double normal with defined initial and final level.  Recommended option. Test using SELEX-24.xls.\\
		26 & 3 & Exponential logistic\\
		27 & 3+2*N\_nodes & Cubic Spline\\
		\hline
	\end{longtable}
\end{center}

\subsubsection{Selectivity Pattern Details}
\underline{Pattern \#1 (size) and \#12 (age) - Simple Logistic}
\begin{itemize}
	\item p1 - size/age at inflection
	\item p2 - width for 95\% selection; a negative width causes a descending curve.
\end{itemize}
Within SS logistic selectivity for the primary gender (if selectivity varies by gender) is formulated as:
\begin{equation}
	S_l = \frac{1.0}{1+exp(-ln(19)(L_l - p1)/p2)}
\end{equation}
where $L_l$ is the length bin.  If age based selectivity is selected then the length bin is replaced by the age vector. If gender specific selectivity is specified the non-primary gender the p1 and p2 parameters are estimated as offsets.  Note that with a large p2 parameter, selectivity may not reach 1.0 at the largest size bin.\\
\hfil
\\
\underline{Pattern \#5 (size) - Mirror Selectivity}\\
Two parameters select the min and max bin number (not min max size) of the source pattern.  If first parameter has value <=0, then interpreted as a value of 1 (e.g. first bin).  If second parameter has value <=0, then interpreted as nlength (e.g. last bin). The source pattern must have a lower type number.\\
\hfil
\\
\underline{Pattern \#6 (size) - Non-parametric selectivity}\\
Non-parametric size selectivity uses a set of linear segments.  The first waypoint is at Length = p1 and the last waypoint is at Length = p2.  The total number of waypoints is specified by the value of the Special factor in the selectivity set-up, so the N intervals is one less than the number of waypoints.  Intermediate waypoints are located at equidistant intervals between p1 and p2.  Parameters 3 to N are the selectivity values at the waypoints, entered as logistic, e.g. $1/(1+exp(-x))$.  Ramps from –10 to p3 if L<p1.  Constant at pN if L>p2.  Note that prior to version 3.03 the waypoints were specified in terms of bin number, rather than length.\\
\hfil
\\
\underline{Pattern \#8 (size) and \#18 (age) - Double Logistic}
\begin{itemize}
		\item  p1 – PEAK:  size (age) for peak. Should be an integer and should be at bin boundary and not estimated.  But options 7 and 18 may allow estimation.
		\item p2 – INIT:  selectivity at lengthbin=1 (minL) or age=0.
		\item p3 – INIT:  selectivity at lengthbin=1 (minL) or age=0. A logit transform $(1/(1+exp(-x))$ is used so that the transformed value will be between 0 and 1.  So a p1 value of –1.1 will be transformed to 0.25 and used to set the selectivity equal to 0.5 at a size (age) equal to 0.25 of the way between minL and PEAK.  (see SS3-selex.xls).
		\item p4 – SLOPE1:  log(slope) of left side (ascending) selectivity.
		\item p5 – FINAL:  logit transform for selectivity at maxL (or maxage).
		\item p6 – INFL2:  logit transform for size(age) at right side selectivity equal to half way between PEAK+PEAKWIDTH and maxL (or max age).
		\item p7 – SLOPE2:  log(slope) of right side (descending) selectivity
		\item p8 – PEAKWIDTH:  in width of flattop.
\end{itemize}
\hfil
\\
\underline{Pattern \#14 (age) - Revise Age}\\
Age-selectivity pattern \#14 to allow selectivity-at-age to be the same as selectivity at the next younger age.  When using this option, the range on each parameter should be approximately -5 to 9 to prevent the parameters from drifting into extreme values with nil gradient. SS calculates the age-based selectivity as:
\begin{equation}
	\begin{split}
			temp = 9 - max(p(1:(nages+1)))\\
			S_a = \frac{1}{1+exp(-(p(a+1) + temp))}
	\end{split}
\end{equation}
\hfil
\\
\underline{Pattern \#17 (age) - Random Walk}\\
This selectivity pattern provides for a random walk in ln(selectivity).  In typical usage:
\begin{itemize}
	\item First parameter (for age 0) could have a value of -1000 so that the age 0 fish would get a selectivity of 0.0;
	\item 	Second parameter (for age 1) could have a value of 0.0 and not be estimated, so age 1 is the reference age against which subsequent changes occur;
	\item 	Next parameters get estimated values.  To assure that selectivity increases for the younger ages, the parameter min for these parameters could be set to 0.0 or a slightly negative value.
	\item If dome-shaped selectivity is expected, then the parameters for older ages could have a range with the max set to 0.0 so they cannot increase further.
	\item To keep selectivity at a particular age the same as selectivity at the next younger age, set its parameter value to 0.0 and not estimated.  This allows for all older ages to have the same selectivity.
	\item 	To keep a constant rate of change in selectivity across a range of ages, use the -999 flag to keep the same rate of change in ln(selectivity) as for the previous age.
\end{itemize}
\begin{center}
	\includegraphics{Selex17_RandomWalk}
\end{center}
\hfil
\\
\underline{Pattern \#9 (size) and \#19 (age) - Simple Double Logistic with no defined peak}
\begin{itemize}
	\item p1 - INFL1:  ascending inflection size (in cm)
	\item p2 – SLOPE1:  ascending slope
	\item p3 – INFL2:  descending inflection size (in cm)
	\item p4 – SLOPE2:  descending slope
	\item p5 – first BIN: bin number for the first bin with non-zero selectivity (must be an integer bin number, not a size)
	\item p6 – offset:  enter 0 if P3 is independent of P1; enter 1 if P3 is an offset from P1
\end{itemize}
\hfil
\\
\underline{Pattern \#22 (size) - Double Normal with Plateau}
\begin{itemize}
	\item p1 – PEAK1:  beginning size for the plateau (in cm)
	\item p2 – PEAK2:  ending size for the plateau.  Calculated as a fraction of the distance between PEAK1 and 99\% of the lower edge of the last size bin in the model.  Transformed as (1/(1+exp(-p2)).   So a value of 0 results in PEAK2 being halfway between PEAK1 and 99\% of the last bin
	\item p3 – upslope:  ln(variance) on ascending side
	\item p4 – downslope:  ln(variance) on descending side
\end{itemize}
\hfil
\\
\underline{Pattern\#23 (size) and \#24 (size) - Double Normal Selectivity}\\

\begin{itemize}
	\item p1 – PEAK:  beginning size for the plateau (in cm)
	\item p2 – TOP:  width of plateau, as logistic between PEAK and MAXLEN
	\item p3 – ASC-WIDTH:  parameter value is ln(width)
	\item p4 – DESC-WIDTH:  parameter value is ln(width)
	\item p5 – INIT:  selectivity at first bin, as logistic between 0 and 1.
	\item p6 – FINAL: selectivity at last bin, as logistic between 0 and 1.  (for pattern \#24) or
	\item p6 – FINAL: selectivity at last bin, as absolute value, so can be >1.0.  (for pattern \#23).  Warning:  Do not allow this value to go above 1.0 if the F\_method uses Pope’s approximation.  OK to go above 1.0 when F is in exponential form.  When this parameter is above 1.0, the overall selectivity pattern will have an intermediate plateau at 1.0 (according to peak and top), then will ascend further to the final value.
\end{itemize}
\hfil
\\
Notes for Double Normal Selectivity:
\begin{itemize}
		\item See spreadsheet SELEX-24.xls for parameterization example.
		\item For the initial selectivity parameter (\#5)
		\begin{itemize}
			\item -999 or –1000:   ignore the initial selectivity algorithm and simply decay the small fish selectivity according to P3,
			\item < -1000:  ignore the initial selectivity algorithm as above and then set selectivity equal to 1.0e-06 for size bins 1 through bin =  -1001 –value.  So a value of –1003 would set selectivity to a nil level for bins 1 through 2 and begin using the modeled selectivity in bin 3.
		\end{itemize}
		\item For the final selectivity parameter (\#6)
		\begin{itemize}
			\item -999 or –1000:   ignore the final selectivity algorithm and simply decay the large fish selectivity according to parameter \#4,
			\item <-1000:  set selectivity constant for bins greater than bin number =  -1000 – value.
		\end{itemize}
\end{itemize}
Selectivity pattern \#24, double normal, showing sub-functions and steep logistic joiners:
\begin{center}
	\includegraphics{DoubleNormal}
\end{center}
\hfil
\\
\underline{Pattern \#15 (age) - Mirror}\\
No parameters.  Whole age range is mirrored from a user-specified fleet.\\
\hfil
\\
\underline{Pattern \#16 - Gaussian (similar to Coleraine)}
\begin{itemize}
	\item p1 – age below which selectivity declines
	\item p2 – scaling factor for decline
\end{itemize}
\hfil
\\
\underline{Pattern \#9 (size) and \#19 (age) - Simple Double Logistic}
\begin{itemize}
	\item p1 – ascending inflection age/size
	\item p2 – ascending slope
	\item p3 – descending inflection age/size
	\item p4 – descending slope
	\item p5 – age or size at first selection; this is a specification parameter, so must not be estimated.  Enter integer that is age for pattern 19 and is bin number for pattern 9
	\item p6 – (0/1)  where a value of 0 causes the descending inflection to be a standalone parameter, and a value of 1 causes the descending inflection to be interpreted as an offset from the ascending inflection.  This is a specification parameter, so must not be estimated.
\end{itemize}
A value of 1.0e-6 is added to the selectivity for all ages, even those below the minage.\\
\hfil
\\
\underline{Pattern \#25 (size) and \#26 (age) - Exponential logistic}
\begin{itemize}
	\item p1 – ascending rate, min: 0.02, max: 1.0, reasonable start value:  0.1
	\item p2 – peak, as fraction of way between min size and max size.  Parameter min value:  0.01; max:  0.99; reasonable start value:  0.5
	\item p2 – minsize + p2*(maxsize-minsize)
	\item p3 – descending rate, min: 0.001, max: 0.5, reasonable start value:  0.01.  A value of 0.001 provides a nearly asymptotic curve.  Values above 0.2 provide strongly dome-shaped function in which the p3 and p1 parameters interact strongly.
\end{itemize}
\begin{equation}
	\frac{e^{p3*p1(p2'-size)}}{1-p3(1-e^{p1(p2'-size)})}
\end{equation}
Example: Exponential logistic selectivity with p1 = 0.30, p2 = 0.50, and p3 = 0.02:\\
\begin{center}
	\includegraphics{ExpLogistic}
\end{center}
\hfil
\\
\underline{Pattern \#27 (size and age)- Cubic Spline}\\
This selectivity pattern uses the ADMB implementation of the cubic spline function. This function requires input of the number of nodes, the positions of those nodes, the parameter values at those nodes, and the slope of the function at the first and last node.  In SS, the number of nodes is specified in the “special” column of the selectivity set-up.  The pattern number 27 is used to invoke cubic spline for size selectivity and for age selectivity; the input syntax is identical.\\
\\
For a 3 node setup, the SS input parameters would be:
\begin{itemize}
	\item p1 – 	code for initial set-up (0, 1 or 2) as explained below
	\item p2 – 	gradient at the first node (should be a small positive value)
	\item p3 – 	gradient at the last node (should be zero or a small negative value)
	\item p4-p6 – the nodes in units of cm; must be in rank order and inside of the range of the population length bins.  These must be held constant (not estimated, e.g. negative phase value) during a model run.
	\item  p7-p9 – the values at the nodes.  Units are ln(selectivity).
\end{itemize}
\hfil
\\
Notes:
\begin{itemize}
	\item There must be at least 3 nodes.
	\item One of these selectivity parameter values should be held constant so others are estimated relative to it.
	\item Selectivity is forced to be constant for sizes greater than the size at the last node
	\item The overall selectivity curve is scaled to have a peak equal to 1.0.
	\item Terminal nodes cannot be at the min or max population length bins.
\end{itemize}

Cubic spline selectivity is implemented within SS using the following code:\\
\begin{center}
	\includegraphics{CubicSplineCode}
\end{center}

The figure below compares a 3 node and a 6 node cubic spline with a 2 parameter logistic function.  In fitting these functions, the 2 cubic spline approaches fit slightly better than the logistic, presumably because the data were slightly indicative of a small dome in selectivity.\\
\begin{center}
	\includegraphics{CubicSpline}
\end{center}
\hfil
\\
Auto-Generation of Cubic Spline Control File Set-Up:\\
A New SS feature pioneered with the cubic spline function is a capability to produce more specific parameter labels and to auto-generate selectivity parameter setup.  The auto-generation feature is controlled by the first selectivity parameter value for each fleet that is specified to use the cubic spline.  There are 3 possible values for this setup parameter:
\begin{itemize}
	\item 0: no auto-generation, process parameter setup as read.
	\item 1: auto-generate the node locations based on the specified number of nodes and on the cumulative size distribution of the data for this fleet/survey.
	\item 2: auto-generate the nodes and also the min, max, prior, init, and phase for each parameter.
\end{itemize}

With either the auto-generate option \#1 or \#2, it still is necessary to include in the parameter file placeholder rows of values so that the init\_matrix command can input the current number of values because all selectivity parameter lines are read as a single matrix dimensioned as N parameters x 14 columns.  The read values of min, max, init, prior, prior type, prior stddev, and phase will be overwritten.

Cumulative size and age distribution is calculated for each fleet, summing across all samples and both genders.  These distributions are output in echoinput.sso and in a new OVERALL\_COMPS section of report.sso.

When the nodes are auto-generated, the first node is placed at the size corresponding to the 2.5\% percentile of the cumulative size distribution, the last is placed at the 97.5\% percentile of the size distribution, and the remainder are placed at equally spaced percentiles along the cumulative size distribution.  These calculated node values are output into control.ss\_new.  So, the user could extract these nodes from control.ss\_new, edit them to desired values, then, insert them into the input control file.  Remember to turn off auto-generation in the revised control file.

When the complete auto-generation is selected, the control.ss\_new would look like the table below.

\begin{center}
	\begin{longtable}{p{1cm} p{1cm} p{1cm} p{1cm} p{1.75cm} p{1cm} p{1.2cm} p{1cm} p{3.8cm}}
		\#LO & HI & INIT & PR & PR\_TYPE & SD & PHASE &  ... & \#Label \\
		\hline
		     0 &     2 &   2.0 & 0 & -1 & 0     & -99 & 0 & \#SizeSpline Code\\
		-0.001 & 	 1 &  0.13 & 0 &  1 & 0.001 & 	3 & 0 & \#SizeSpline GradLo\\
			-1 & 0.001 & -0.03 & 0 &  0 & 0.001 & 	3 & 0 & \#SizeSpline GradHi\\
			11 & 	95 & 	38 & 0 & -1 & 	  0 & -99 & 0 & \#SizeSpline Knot1\\
			11 & 	95 & 	59 & 0 & -1 &     0 & -99 & 0 & \#SizeSpline Knot2\\
		    11 & 	95 & 	74 & 0 & -1 & 	  0 & -99 & 0 & \#SizeSpline Knot3\\
			-9 & 	 7 & 	-3 & 0 &  1 & 0.001 & 	2 & 0 & \#SizeSpline Value1\\
			-9 &   	 7 & 	-1 & 0 & -1 & 0.001 &  99 & 0 & \#SizeSpline Value2\\
			-9 & 	 7 & -0.78 & 0 &  1 & 0.001 & 	2 & 0 & \#SizeSpline Value3\\
		\hline
	\end{longtable}
\end{center}
\hfil\\
\underline{Survey Pattern \#34 - Depletion}\\
This option allows a specified degree of stock depletion (in terms of spawning biomass) to be entered as the ratio of current year’s spawning biomass relative to Bzero.  With this option, it is not necessary or reasonable to estimate the Q for this fleet, but you must set ln(Q) = 0.0 as a fixed value for absolute abundance.  Also, if this option is used, then automatic adjustments to phase and lambda are made such that:

\begin{itemize}
	\item all parameter phases are adjusted by +1 so that only R0 is active in phase 1
	\item all lambdas are set to 0 in phase 1, except the lambda for this depletion survey.  Internally, the flag "depletion\_fleet" is turned on (= to the index of that fleet) if there is a fleet with selex = \#34
\end{itemize}

Essentially, these automated features cause SS to mimic DB-SRA in phase 1.  If the model is only run through phase 1, then this will be the final result.  Alternatively, use of this option could just be used to get the R0 parameter into a reasonable range before proceeding to estimate other parameters.  The lambda for the depletion survey could remain at 1.0 for the entire model run, or it could be reduced in later phases to prevent influencing final model results.

\subsubsection{Retention}
Retention is defined as a logistic function of size.  It does not apply to surveys.  Four parameters are used:
\begin{itemize}
	\item p1 – inflection
	\item p2 – slope
	\item p3 – asymptotic retention (often a time-varying quantity to match the observed amount of discard)
	\item p4 – male offset to inflection (arithmetic, not multiplicative)
\end{itemize}
\begin{equation}
	Retention = \frac{P3}{1 + e^{\frac{-(L-(P1+P4*male))}{P2}}}
\end{equation}

\subsubsection{Discard Mortality}
Discard mortality is defined as a logistic function of size such that mortality declines from 1.0 to an asymptotic level as fish get larger.  It does not apply to surveys and it does not affect the calculation of expected values for discard data.   It is applied so that the total mortality rate is:\\
\begin{center}
	deadfish = selex * (retain + (1.0-retain)*discmort)
\end{center}
If discmort is 1.0, all selected fish are dead; if discmort is 0.0, only the retained fish are dead.

Four parameters are used:
\begin{itemize}
	\item p1 – inflection
	\item p2 – slope
	\item p3 – asymptotic mortality
	\item p4 – male offset to inflection (arithmetic, not multiplicative)
\end{itemize}

Discard mortality is calculated as:
\begin{equation}
	Mortality = 1 - \frac{1-P3}{1+e^{\frac{-(L-(P1+P4*male))}{P2}}}
\end{equation}

\subsubsection{Male Selectivity}
There are two approaches to specifying gender specific selectivity.  One approach allows male selectivity to be specified as a fraction of female selectivity (or vice versa).  This first approach can be used for any selectivity pattern.  The other option allows for separate selectivity parameters for each gender plus an additional parameter to define the scaling of one gender’s peak selectivity relative to the other gender’s peak.  This second approach has only been implemented for a few selectivity patterns.\\
\\
Approach \#1:\\
If the “domale” flag is set to 1, then the selectivity parameters define female selectivity and the offset defined below sets male selectivity relative to female selectivity.  The two genders switch roles if the “domale” flag is set to 2.  Generally it is best to select the option so that the dependent gender has lower selectivity, thus obviating the need to rescale for selectivities that are greater than 1.0.  Gender specific selectivity is done the same way for all size and age selectivity options.
\begin{itemize}
	\item P1 – size (age) at which a dogleg occurs (set to an integer at a bin boundary and do not estimate)
	\item P2 – log(relative selectivity) at minL or age=0.  Typically this will be set to a value of 0.0 (for no offset) and not estimated.  It would be a rare circumstance in which the youngest/smallest fish had gender-specific selectivity.
	\item P3 – log(relative selectivity) at the dogleg
	\item P4 – log(relative selectivity) at maxL or max age.
\end{itemize}

For intermediate ages, the log values are linearly interpolated on size (age).

If selectivity for the dependent gender is greater than the selectivity for the first gender (which always peaks at 1.0), then the male-female selectivity matrix is rescaled to have a maximum of 1.0.\\
\\
Approach \#2:\\
A new gender selectivity option (3 or 4) has been implemented for size selectivity patterns 1 (logistic) and 23 and 24 (double normal) or age selectivity pattern 20 (double normal age).  Rather than calculate male selectivity as an offset from female selectivity, here the male selectivity is calculated by making the male parameters an offset from the female parameters (option 3), or females are offset from males with option 4.  The description below applies to option 3. If the size selectivity pattern is 1 (logistic), then read 3 parameters:
\begin{itemize}
	\item male parm 1 is added to the first selectivity parm (inflection)
	\item male parm 2 is added to the second selectivity parm (width of curve)
	\item male parm 3 is the asymptotic selectivity
\end{itemize}

If the size selectivity pattern is 20, 23 or 24 (double normal), then:
\begin{itemize}
	\item male parm 1 is added to the first selectivity parm (peak)
	\item male parm 2 is added to the third selectivity parm (width of ascending side); then exp(this sum) per previous transform
	\item male parm 3 is added to the fourth selectivity parm (width of descending side); then exp(sum) per previous transform
	\item male parm 4 is added to the sixth selectivity parm (selectivity at final size bin); then 1/(1+exp(-sum)) per previous transform
	\item male parm 5 is the apical selectivity for males
\end{itemize}

Note that the male selectivity offsets currently cannot be time-varying (need to check on this).  Because they are offsets from female selectivity, they inherit the time-varying characteristics of the female selectivity.

\subsubsection{Reading the Selectivity and Retention Parameters}
Read the required number of parameter setup lines as specified by the definition lines above.  The complete order of the parameter setup lines is:
\begin{enumerate}
	\item Size selectivity for fishery 1
	\item Retention for fishery 1
	\item Male offsets for size selectivity for fishery 1
	\item <repeat for additional fleets and surveys>
	\item Age selectivity for fishery 1
	\item Male offsets for age selectivity for fishery 1
	\item <repeat for additional fleets and surveys>.
\end{enumerate}

The time-varying options for selectivity parameters are identical to the time-varying options for biology parameters.  These options are described below in the Time-Varying Parameter Options section.  After reading the selectivity parameters, which will include possible instructions to create environmental link, blocks, or dev vectors, then read the following section.  Note that all inputs in this section are conditional (COND) on entries in the selectivity parameter section.  So if no selectivity parameters invoke any time-varying properties, this section is left blank (or completely commented out with \#).

\begin{center}
	\begin{longtable}{p{2cm} p{1cm} p{4cm} p{8cm}}
		Value & & Label & Description\\
		\hline
		\endfirsthead

		Value & & Label & Description\\
		\hline
		\endhead

		\endfoot

		\endlastfoot

			%Value & & Label & Description \\
			COND &  & & If any selectivity parameters use environmental linkage, then read next line and associated parameter line(s).\\
			     & 0 & Custom Environmental Linkage	& \\
			\hline
			COND &  & & If custom=0, then read one parameter line below and apply to all env functions;
			If custom>0, then read a setup line for each SEL-parm with Env-var>0. Note that control.ss\_new will write out with custom=1 so it can write all the parameter values.\\
			\hline
			\multicolumn{4}{l}{Enter proper number of short set-up lines (0, 1, several) for the SEL-parm environmental}\\
			\multicolumn{4}{l}{linkages.  Each line will have 7 values:  LO, HI, INIT, PRIOR, PR\_type, SD, PHASE.}\\
			\hline
			COND & & & If any selectivity parameters use time blocks, then read next line and associated parameter line(s). \\
			     & 0 & Custom block setup & If custom=0, then read one setup and apply to all Block fxns;
			     If custom>0, then read a setup line for each SEL-parm with Block>0.  \\
			\hline
			\multicolumn{4}{l}{Enter proper number of short set-up lines (0, 1, several) for the SEL-parm block linkages.}\\
			\multicolumn{4}{l}{Each line will have 7 values:  LO, HI, INIT, PRIOR, PR\_type, SD, PHASE.} \\
			\hline
			COND &  & & If any selectivity parameters use annual devs, then read  value\\
			     & -4 & Selparm dev phase & Phase in which selparm devs, if any, are estimated. \\
			\hline
			COND &  & & If any selectivity parameters use environmental links, blocks or annual devs, then read value.\\
			     & 2 & Selparm Adjust Method & 1 = parameter adjustments for env, block and dev are applied directly and resulting value is not compared to base parameter bounds\\
			     &   & & 2 = parameter adjustments use a logistic transformation to assure that adjusted parameter value stays within bounds of base parameter.\\
			\hline
	\end{longtable}
\end{center}

\subsubsection{Tag Recapture Parameters}
Specify if tagging data are being used:
\begin{center}
	\begin{longtable}{p{0.75cm} p{0.75cm} p{0.75cm} p{1.25cm} p{1.75cm} p{1cm} p{1.5cm} p{0.75cm} p{4.5cm}}

		\multicolumn{3}{l}{Value} &  \multicolumn{3}{l}{Label} & \multicolumn{3}{l}{Description}\\
		\hline
		\multicolumn{3}{l}{1} &  \multicolumn{3}{l}{Tagging Data Present} & \multicolumn{3}{l} {0 = no read}\\
		\multicolumn{3}{l}{} &  \multicolumn{3}{l}{} & \multicolumn{3}{l} {1 = read following lines}\\
		\\
		\multicolumn{8}{l}{COND = 1}\\
		\#LO & HI & INIT & PRIOR & PR\_TYPE& SD & PHASE & ... & LABEL\\
		\hline
		-10 & 10 & 9 & 9 & 1 & 0.001 & -4 & 0 & \#TG loss init 1\\
		-10 & 10 & 9 & 9 & 1 & 0.001 & -4 & 0 & \#TG loss init 2\\
		-10 & 10 & 9 & 9 & 1 & 0.001 & -4 & 0 & \#TG loss init 3\\
		-10 & 10 & 9 & 9 & 1 & 0.001 & -4 & 0 & \#TG loss chronic1\\
		-10 & 10 & 9 & 9 & 1 & 0.001 & -4 & 0 & \#TG loss chronic2\\
		-10 & 10 & 9 & 9 & 1 & 0.001 & -4 & 0 & \#TG loss chronic3\\
		  1 & 10 & 2 & 2 & 1 & 0.001 & -4 & 0 & \#TG loss overdisperion1\\
		  1 & 10 & 2 & 2 & 1 & 0.001 & -4 & 0 & \#TG loss overdisperion2\\
		  1 & 10 & 2 & 2 & 1 & 0.001 & -4 & 0 & \#TG loss overdisperion3\\
		-10 & 10 & 9 & 9 & 1 & 0.001 & -4 & 0 & \#TG report fleet1\\
		-10 & 10 & 9 & 9 & 1 & 0.001 & -4 & 0 & \#TG report fleet2\\
		 -4 &  0 & 0 & 0 & 0 &     2 & -4 & 0 & \#TG report decay1\\
		 -4 &  0 & 0 & 0 & 0 &     2 & -4 & 0 & \#TG report decay2\\
		 \hline
	\end{longtable}
\end{center}

The tagging reporting rate parameter is transformed within SS during estimation to maintain a positive value and is reported according to the transformation:
\begin{equation}
	Tagging\_Reporting\_Rate = \frac{e^{input\_parameter}}{1+e^{input\_parameter}}
\end{equation}

\subsubsection{Variance Adjustment Factors}
When doing iterative reweighting of the input variance factors, it is convenient to do this in the control file, rather than the data file.  This section creates that capability.
\begin{center}
	\begin{longtable}{p{3cm} p{3cm} p{7cm} }

		%Value & Description & & Options & \\
		%\hline
		%0 & \multicolumn{2}{l}{Variance Adjustment Factors } & \multicolumn{2}{l}{0 = none, 1 = read table}\\
		 \multicolumn{3}{l}{Variance Adjustment Factors }\\
		 \hline
		-9999 1 0 & \multicolumn{2}{l}{No variance adjustment factors applied }\\
		\\
		\multicolumn{3}{l}{If variance adjustment factors are to be applied:}\\
		\hline
		%Fleet/Survey 1 & Fleet/Survey 2 & Fleet/Survey 3 & Fleet/Survey 4 & Label \\
		Factor & Fleet & Value \\
		\hline
		1 & 2 & 0.5 \\
		4 & 1 & 0.25 \\
		4 & 2 & 0.75 \\
		%0 & 0 & 0 & 0 & \#Survey CV\\
		%0 & 0 & 0 & 0 & \#Discard CV\\
		%0 & 0 & 0 & 0 & \#Mean BodyWght SD\\
		%1 & 1 & 1 & 1 & \#Length Comp\\
		%1 & 1 & 1 & 1 & \#Age Comp\\
		%1 & 1 & 1 & 1 & \#Size-at-Age\\
		\hline
	\end{longtable}
\end{center}

\begin{description}
	\item[Survey CV - Factor 1]\hfil\\
	The survey input variance (labeled survey CV) is actually the standard deviation of the ln(survey).  The variance adjustment is added directly to this standard deviation.  Set to 0.0 for no effect.  Negative values are OK, but will crash if adjusted value becomes negative.
	\item[Discard - Factor 2]\hfil\\
	The input variance is the CV of the observation.  Because this will cause observations of near zero discard to appear overly precise, the variance adjustment is added to the discard standard deviation, not to the CV.  Set to 0.0 for no effect.
	\item[Mean Body Weight - Factor 3]\hfil\\
	The input variance is in terms of the CV of the observation.  Because such data are typically not very noisy, the variance adjustment is added to the CV and then multiplied by the observation to get the adjusted standard deviation of the observation.
	\item[Length Composition - Factor 4]\hfil\\
	The input variance is in terms of an effective sample size.  The variance adjustment is multiplied times this sample size.  Set variance adjustment to 1.0 for no effect.
	\item[Age Composition - Factor 5]\hfill\\
	Age composition is treated the same way as length composition.
	\item[Size-at-Age - Factor 6]\hfill\\
	Size-at-age input variance is the sample size for the N observations at each age.  The variance adjustment is multiplied times these N values. Set to 1.0 for no effect.
	\item[Generalized Size Comp - Factor 7]\hfill\\
	Not yet implemented
	\item[Usage Notes]\hfill
	\begin{itemize}
		\item The report.sso output file contains information useful for determining if an adjustment of these input values is warranted to better match the scale of the average residual to the input variance scale.
		\item Because the actual input variance factors are modified, it is these modified variance factors that are used when creating parametric bootstrap data files.  So, the control files used to analyze bootstrap generated data files should have the variance adjustment factors reset to null levels.
	\end{itemize}
\end{description}

\subsubsection{Lambdas (Emphasis Factors)}
These values are multiplied by the corresponding likelihood component to calculate the overall negative log likelihood to be minimized.

\begin{center}
	\begin{tabular}{p{2cm} p{14cm}}
		Value & Description \\
		\hline
		4 & Max\_lambda\_phase: read this number of lambda values for each element below.  The last lambda value is used for all higher numbered phases.\\
		1 & sd\_offset; value=0 causes log(like) to omit the +log(s) term; value=1 causes log(like) to include the log(s) term for CPUE, discard, meanbodywt, recruitment deviations. \\
		\hline
	\end{tabular}
\end{center}

\begin{description}
	\item[Usage Note:]\hfil\\
	If the CV for size-at-age is being estimated and the model contains mean size-at-age data, then the flag for inclusion of the +log(stddev) term in the likelihood must be included.  Otherwise, the model will always get a better fit to the mean size-at-age data by increasing the parameter for CV of size-at-age.
\end{description}

The reading of the lambda values has been substantially altered with SS\_v3.  Instead of reading a matrix containing all the needed lambda values, SS now just reads those elements that will be given a value other than 1.0.  After reading the datafile, SS sets lambda equal to 0.0 if there are no data for a particular fleet/data type, and a value of 1.0 if data exist.  So beware if your data files had data but you had set the lambda to 0.0 in a previous version of SS.  First read an integer for the number of changes.

\begin{center}
	\begin{longtable}{p{3cm} p{3cm} p{2cm} p{3cm} p{3cm}}
		\hline
		%3 & \multicolumn{4}{l}{\#Number of changes to make to default lambdas (default value is 1.0)}\\
		\multicolumn{5}{l}{\#Then read that number of lines containing the change information:}\\
		\#Component & Fleet/Survey & Phase & Lambda & SizeFreq Method \\
		\hline
		1 & 2 & 2 & 1.5 & 1 \\
		4 & 2 & 2 & 10 & 1 \\
		4 & 2 & 3 & 0.2 & 1 \\
		-9999 & 1 & 1 & 1 & 1 \\
		\hline
	\end{longtable}
\end{center}

\begin{center}
	\begin{longtable}{p{16cm}}
		The codes for component are:\\
		1 = survey;\\
		2 = discard;\\
		3 = mean weight;\\
		4 = length;\\
		5 = age; \\
		6 = size frequency;\\ 
		7 = size-at-age; \\
		8 = catch; \\
		9 = initial equilibrium catch;\\
	    10 = recruitment deviations; \\
		11 = parameter priors; \\
		12 = parameter deviations;\\ 
		13 = crash penalty; \\
		14 = morph composition;v 
		15 = tag composition;\\
		16 = tag negbin.\\
	\end{longtable}
\end{center}

\begin{center}
	\begin{longtable}{p{2cm} p{2cm} p{2cm} p{2cm} p{6cm}}
		\hline		
		\endfirsthead

		\hline
		\endhead
		\hline
				
		\endfoot
		\endlastfoot
		
		\multicolumn{5}{l}{On output to control.ss\_new, the full table is written:}\\
		\multicolumn{5}{l}{\#Lambdas (for information only; columns are phases)}\\
		\hline
		\# 0 & 0 & 0 & 0 & \#CPUE/survey: 1\\
		\# 1 & 1.5 & 1.5 & 1.5 & \#CPUE/survey: 2\\
		\# 1 & 1 & 1 & 1 & \#CPUE/survey: 3\\
		\# 1 & 1 & 1 & 1 & \#lencomp: 1\\
		\# 1 & 10 & 2 & 2 & \#lencomp: 2\\
		\# 0 & 0 & 0 & 0 & \#lencomp: 3\\
		\# 1 & 1 & 1 & 1 & \#agecomp: 1\\
		\# 1 & 1 & 1 & 1 & \#agecomp: 2\\
		\# 0 & 0 & 0 & 0 & \#agecomp: 3\\
		\# 1 & 1 & 1 & 1 & \#size-at-at-age: 1\\
		\# 1 & 1 & 1 & 1 & \#size-at-at-age: 2\\
		\# 0 & 0 & 0 & 0 & \#size-at-at-age: 3\\
		\# 1 & 1 & 1 & 1 & \#init\_equil\_catch \\
		\# 1 & 1 & 1 & 1 & \#recruitments \\
		\# 1 & 1 & 1 & 1 & \#parameter priors\\
		\# 1 & 1 & 1 & 1 & \#parameter dev vectors\\
		\# 1 & 1 & 1 & 1 & \#crash penalty lambda\\
		\hline
	\end{longtable}
\end{center}

\subsubsection{Controls for Variance of Derived Quantities}
Add option to get variance estimates for one selectivity pattern and for size-at-age.  At the end of the control file, just before the "999", add:
\begin{center}
	\begin{longtable}{p{1cm} p{1.2cm} p{1.2cm} p{1.2cm} p{1.2cm} p{1.2cm} p{1.5cm} p{1.5cm} p{1.8cm}}
		\hline
		1 & \multicolumn{8}{l}{0 = no additional std dev reporting, 1 = read values}\\
		\multicolumn{2}{l}{COND > 0} & \multicolumn{7}{l}{If the above value is "0", then do not include any more entries.}\\
		  & & \multicolumn{7}{l}{If the above value is "1", then read 9 more integers:}\\
		\#Fleet & Len/Age & Year & Nselex Bins & Growth Pattern & Ngrowth Areas & Area for Natage & Year for Natage & N ages to report\\
		\hline
		1 & 1 & -1 & 7 & 1 & 5 & -1 & -1 & 5\\
		\hline
	\end{longtable}
\end{center}

Where:
\begin{itemize}
	\item FLEET:  is the index of the fleet to be output.  A value of zero causes there to be no selectivity variance output;
	\item LEN/AGE:  enter "1" to select length selex or "2" to select age selectivity.  There is no option to get the combined age selectivity that incorporates the size selectivity;
	\item YEAR:  enter a value for the selected year, or enter -1 to get the selectivity in the end year
	\item 	N Selectivity bins:  enter the number of bins for which selectivity will be output.  This number controls the number of items to be read below, even if the FLEET is set to zero.  In other words, the read occurs even if the effect of the read is disabled.
	\item GROWTH PATTERN:  growth pattern is the number of the growth pattern to be output.  Enter "0" to get no variance output for size-at-age.   Note that in a multiple season model, SS will output the size-at-age for the last birth season that gets any recruits within the year.  Also, if growth parameters are not estimated, then stddev output of mean size-at-age is disabled.
	\item 	N growth bins:  Number of ages for which size-at-age variance is requested.  This number controls the number of items to be read below, even if the growth pattern selection is set to zero.   In other words, the read occurs even if the effect of the read is disabled.
	\item 	Area:  specifies the area for which output of numbers at age is requested.  A value of 0 disables this output.  A value of -1 requests that numbers-at-age be summed across all areas.  In all cases, numbers-at-age is summed across all growth patterns and sub-morphs and output for each gender.
	\item 	Year:  specifies the year for which numbers-at-age are output.  A value of -1 requests output for year equal to endyear+1, hence the year that starts the forecast period.
	\item N numbers-at-age bins:  as with the N growth bins.
\end{itemize}
For size selex, these are population bin numbers.  For age selex, they refer directly to age.  Entering a negative value for the first bin causes SS to self-generate an evenly spaced set.

\begin{center}
	\begin{tabular}{p{4cm} p{12cm}}
		\hline
		5 10 16 22 27 38 46 & \#Vector with selex std bin picks (-1 in first bin to self generate)\\
		\hline
	\end{tabular}
\end{center}
If the number of growth bins to be output is >0, then read a vector of ages to be output.  Entering a negative value for the first bin causes SS to self-generate a set that begins at AFIX, ends at Nages, and is denser at younger ages.
\begin{center}
	\begin{tabular}{p{4cm} p{12cm}}
		\hline
		1 2 14 26 40 & \#Vector with growth std bin picks (-1 in first bin to self generate)\\
		\hline
	\end{tabular}
\end{center}
If the number of numbers-at-age bins to be output is >0, then read a vector of ages to be output.  Entering a negative value for the first bin causes SS to self-generate a set that begins at 1, ends at Nages, and is denser at younger ages.
\begin{center}
	\begin{tabular}{p{4cm} p{12cm}}
		\hline
		1 2 14 26 40 & \#Vector with n-at-age std bin picks (-1 in first bin to self generate)\\
		\hline
	\end{tabular}
\end{center}

\begin{center}
	\begin{longtable}{p{1cm} p{1cm} p{1cm} p{1cm} p{1cm} p{1cm} p{1cm} p{1cm} p{1cm} p{3.5cm}}

		\multicolumn{10}{l}{So a complete input looks like:}\\
		\hline
		1 & & \multicolumn{8}{l}{\# 0 = no additional input, 1 = read stdev reporting lines}\\
		\hline
		\multicolumn{10}{l}{COND > 0}\\
		& 1 & 1 & -1 & 5 & 1 & 5 & 1 & -1 & 5 \\
		& 5 & 16 & 27 & 38 & 46 & \multicolumn{4}{l}{\#Vector with selex std bin picks}\\
		& 1 & 2 & 14 & 26 & 40 & \multicolumn{4}{l}{\#Vector with growth std bin picks}\\
		& 1 & 2 & 14 & 26 & 40 & \multicolumn{4}{l}{\#Vector with n-at-age std bin picks}\\
		\hline
		\\
		\multicolumn{10}{l}{End Control File Input}\\
		\bfseries{999} & \multicolumn{9}{l}{\#End of file}
	\end{longtable}
\end{center}

\subsubsection{Time-Varying Parameter Options}
Biology parameters and selectivity parameters can vary over time.  There are four options for time-varying parameters:  blocks, trends, environmental linkage, and annual deviations.

Elements 8 through 14 of the full parameter lines are used to setup the time-varying properties.  If any parameter of the biology section is made to be time-varying, then one or more conditional inputs at the end of the biology section (or end of the selectivity section) will need to be turned on, and one or more parameter lines will need to be inserted to contain the parameter linkages and offsets that have been selected.  This is done separately for the block of biology parameters and then for the selectivity parameters.

With version SS v3, the options for time-varying parameters have been expanded to include more additive effects.  This is because it is not logical for a parameter whose range spans 0.0 to have a time-varying effect defined in a multiplicative way.  This is especially true for those parameters that are exponentiated as they are being used.  For example, the parameters that define the allocation of recruitment among areas and seasons should be made time-varying only through an additive function.
The order in which time-varying effects are calculated is:  first blocks or trends, then environmental effects, then annual deviations.

All time-varying options work on an annual time step, so in a multi-season model the parameters remain constant for the entire year.  The exception is for the select biology parameters that have a separate capability to vary seasonally.

If the parameter adjustment method is set to a value of 2, then each parameter time-varying adjustments has an intermediate logistic transformation so the adjusted parameter stays within the min-max bounds of the parameter being adjusted.  With this method, multiplicative adjustments are not implemented and the additive adjustments are in the domain of the logistic transformed base parameter.  So, the adjustment coefficients will not have intuitive values.

The available options for time-varying parameters are described below:
\begin{itemize}
	\item Env Var - Element 8 in parameter setup
		\begin{itemize}
			\item >0: multiplicative
			\item <0: additive
			\item abs(value): environmental index
		\end{itemize}
	\item Use Dev - Element 9 in parameter setup
	\begin{itemize}
		\item 1: multiplicative
		\item 2: additive
		\item 3: additive random walk
	\end{itemize}
	\item Dev minyr - Element 10 in parameter setup
	\begin{itemize}
		\item Year for deviations to start for parameter
	\end{itemize}
	\item Dev maxyr - Element 11 in parameter setup
		\begin{itemize}
			\item Year for deviations to end for parameter
		\end{itemize}
	\item Dev StdDev - Element 12 in parameter setup
		\begin{itemize}
			\item Standard deviation for deviations
		\end{itemize}
	\item Blocks - Element 13 in parameter setup
		\begin{itemize}
			\item >0: block index for parameter
			\item <0: trend
		\end{itemize}
	\item Block Functional Form: Element 14 in parameter setup
		\begin{itemize}
			\item 0: multiplicative
			\item 1: additive
			\item 2: replace
			\item 3: random walk
		\end{itemize}
\end{itemize}
\begin{center}
	\begin{longtable}{p{2cm} p{2cm} p{2cm} p{2cm} p{2cm} p{2.25cm} p{1.75cm}}
		\multicolumn{7}{l}{Example of location for specifying time-varying parameters}\\
		\hline
		Env Var & Use Dev & Dev Minyr & Dev Maxyr & Dev StDev & Blocks & Block Fxn\\
		\hline
		>0: mult & 1:mult & 1973 & 1985 & 0.40 & block index & 0:mult\\
		\hline
	\end{longtable}
\end{center}
\begin{center}
	\includegraphics{TimeVarying}
\end{center}
\begin{center}
	\begin{longtable}{p{2.5cm} p{13cm}}
		\hline
		ENV & A positive value, g, causes SS to set the annual working value of this parameter equal to a multiplicative function of Environmental Variable\\
		    & \multicolumn{1}{c}{g:parm’(y) = parm * exp(link * env(y,g))} \\
			& A negative value, g, causes SS to set the annual working value of this parameter equal to a additive function of Environmental Variable g:\\
		    & \multicolumn{1}{c}{parm’(y) = parm + link * env(y,-g)}\\
			& Where, link is the environmental link parameter, parm is the base parameter being adjusted, parm’ is the value after adjustment, and env(y,-g) is the value of the environmental input g in year y. SS counts the number of parameters that invoke use of an Environmental Variable.  After SS finishes reading the section’s parameter lines, it then creates/reads additional short parameter line(s) to set up the link parameters.  If custom=0, then one short parameter line is used to define the min, max, init, etc, for each of the link parameters.  If custom=1, then a separate line is read for each.\\
		\hline
		Use\_Dev & A value of 1 invokes multiplicative:  parm’(y) = parm * exp(dev(y))\\
			& A value of 2 invokes additive:  parm’(y) = parm + dev(y)\\
			& A value of 3 invokes additive random walk:  parm’(y) = parm’(y-1) + dev(y)\\
		    & The vector of devs is simply a vector of offsets; there is no inherent sum to zero constraint.  However, the fact that they are each penalized by the DEV std.dev. below will tend to make them sum towards 0.0.\\
		\hline
		Dev min yr & Beginning year for the dev vector for this parameter\\
		\hline
		Dev max yr & Ending year for the dev vector for this parameter\\
		\hline
		Dev Std Dev. & Standard deviation for elements in the dev vector for this parameter \\
		\hline
		Use Block & Block: A positive value identifies which block pattern will be used for time changes to a parameter value.  Block patterns are simply numbered sequentially as they are defined near the top of the control file, so the index here must be correct for the order in which they are defined.  More than one parameter can use the same block definition.  The order of generated block parameters is by the order of the parameters that call for creation of the block parameters, then by the order of the blocks within that pattern. \\
				  & Trend:  A negative value for the Use\_Block input causes SS to create a parameter time trend instead of blocks.  This time trend requires 3 parameters (instead of the normal one parameter per block).  The base parameter is the value for the adjusted parameter in year = start year.  For subsequent years, the three parameters define a normal distribution of change over time:\\
				  & P1:  parameter value for year = end year.  Either as logistic offset from base P (if Use\_Block=-1), or as direct usage (if Use\_Block=-2)\\
				  & P2:  inflection year;  if HI value for the base parameter is >1.1, then use as year, else use as fraction of range styr - endyr\\
				  & P3:  width of change (units of std.dev. of years)\\
		\hline
		Block Type & This selects the way in which the block parameter creates an offset from the base parameter. \\
				   & 0 means that parm’ = baseparm * exp(blockparm)\\
				   & 1 means that parm’ = baseparm + blockparm\\
				   & 2 means that parm’ = blockparm\\
				   & 3 means that parm’ = is additive offset from previous block.  Note that blocks must be contiguous to use this option properly.\\
		\hline
	\end{longtable}
\end{center}

\subsubsection{Parameter Priors}
Priors on parameters fulfill two roles in SS.  First, for parameters provided with an informative prior, SS is receiving additional information about the true value of the parameter.  This information works with the information in the data through the overall logL function to arrive at the final parameter estimate.  Second, diffuse priors provide only weak information about the value of a prior and serve to manage model performance during execution.  For example, some selectivity parameters may become unimportant depending upon the values of other parameters of that selectivity function.  In the double normal selectivity function, the parameters controlling the width of the peak and the slope of the descending side become redundant if the parameter controlling the final selectivity moves to a value indicating asymptotic selectivity.  The width and slope parameters would no longer have any effect on the logL, so they would have no gradient in the logL and would drift aimlessly.  A diffuse prior would then steer them towards a central value and avoid them crashing into the bounds.  Another benefit of diffuse priors is the control of parameters that are given unnaturally wide bounds.  When a parameter is given too broad of a bound, then early in a model run it could drift into this tail and potentially get into a situation where the gradient with respect that parameter approaches zero even though it is not at its global best value.  Here the diffuse prior helps move the parameter back towards the middle of its range where it presumably will be more influential and estimable.  The options for parameter priors are:
\begin{itemize}
	\item -1 = No prior applied.
	\item  0 = Normal prior. Note that this function is independent of the parameter.
	\begin{equation}
		Pr\_Like = 0.50*(\frac{Pval - Prior}{Prior\_SD})^2
	\end{equation}
	\item  1 = Symmetric bet prior is scaled between parameter bounds, imposing a larger penalty near the bounds.  Prior standard deviation of 0.05 is very diffuse and a value of 5.0 provides a smooth U-shaped prior.
	\begin{equation}  \mu = -P\_SD*(log((Pmax+Pmin)*0.5-Pmin)-P\_SD*(log(0.5)) \end{equation}
	\begin{equation}
		\begin{split}
			Prior\_Like = -(\mu + (P\_SD*(log(Pval-Pmin+Pconst))) + \\
			(P\_SD*(log(1-(\frac{(Pval-Pmin-Pconst)}{(Pmax-Pmin)})))))
		\end{split}
	\end{equation}

	\begin{center}
			\includegraphics{Beta}\\
			Prior distributions for the symmetric beta distribution.
	\end{center}

	\item 2 = Beta prior.  The definition of $\mu$ is consistent with CASAL's formulation with the Bprior and Aprior corresponding to the m and n parameter.
	\begin{equation}
		\begin{split}
			\mu = \frac{Prior-Pmin}{Pmax-Pmin} \\
			\tau  = \frac{(Prior-Pmin)(Pmax-Prior)}{P\_SD^2}-1.0\\
			Bprior  = \tau*\mu; Aprior = \tau (1.0-\mu)\\
		\end{split}
	\end{equation}
		\begin{equation}
		\begin{split}
		Prior\_Like = (1.0-Bprior)*log(Pconst+Pval-Pmin) + \\
		(1.0-Aprior)*log(Pconst+Pmax-Pval) - \\
		(1.0-Bprior)*log(Pconst + Prior - Pmin) - \\
		(1.0-Aprior)*log(Pconst + Pmax - Prior)
		\end{split}
	\end{equation}

	\begin{center}
		\includegraphics{BetaComparison}\\
		Comparison of the symmetric beta and the beta prior functions
	\end{center}

	\item 3 = Lognormal prior.  Note that lower bound on the parameter must be >0.0. The prior value is input into the parameter line in log space while the initial parameter value is defined in normal space (e.g. INIT = 0.20, PRIOR = -1.609438).
	\begin{equation}
		Prior\_Like = 0.50*\Big(\frac{(log(Pval)-Prior)}{Pr\_SD}\Big)^2
	\end{equation}
	\item Pval is the value of the parameter for which a prior is being calculated, Pmin and Pmax are the bounds on the parameter, Prior is the value of the parameter prior, or the first of the 2 factors controlling the calculation of the prior, Pr\_SD is the value of the prior's standard deviation, or the second of the 2 factors controlling the calculation of the prior, Pconst is a small constant (0.0001), and Prior\_Like is the calculated value of the prior's contribution to the log likelihood.
\end{itemize}
